{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "NVIDIA A100-PCIE-40GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time as time\n",
    "\n",
    "import torch\n",
    "\n",
    "M1 = False\n",
    "\n",
    "if M1:\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "else:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(torch.cuda.is_available())\n",
    "        print(torch.cuda.device_count())\n",
    "        print(torch.cuda.current_device())\n",
    "        print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import skimage as ski\n",
    "\n",
    "import quantifai as qai\n",
    "from quantifai.utils import to_numpy, to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimisation options for the MAP estimation\n",
    "options = {\"tol\": 1e-5, \"iter\": 15000, \"update_iter\": 4999, \"record_iters\": False}\n",
    "# Save param\n",
    "repo_dir = \"./../../..\"\n",
    "base_savedir = \"/disk/xray99/tl3/proj-convex-UQ/outputs/new_UQ_results/wavelets\"\n",
    "save_dir = base_savedir + \"/vars/\"\n",
    "savefig_dir = base_savedir + \"/figs/\"\n",
    "\n",
    "# Define my torch types (CRR requires torch.float32, wavelets require torch.float64)\n",
    "myType = torch.float64\n",
    "myComplexType = torch.complex128\n",
    "\n",
    "# Wavelet parameters\n",
    "reg_params = [1e2]  # [5e2] # [5e2, 5e1, 1e3, 5e3, 1e4, 5e4]\n",
    "wavs_list = [\"db8\"]\n",
    "levels = 4\n",
    "\n",
    "# LCI params\n",
    "alpha_prob = 0.01\n",
    "\n",
    "# LCI algorithm parameters (bisection)\n",
    "LCI_iters = 200\n",
    "LCI_tol = 1e-4\n",
    "LCI_bottom = -10\n",
    "LCI_top = 10\n",
    "\n",
    "# Compute the MAP-based UQ plots\n",
    "superpix_MAP_sizes = [16, 8]  # [32, 16, 8, 4]\n",
    "# Clipping values for MAP-based LCI. Set as None for no clipping\n",
    "clip_high_val = 1.0\n",
    "clip_low_val = 0.0\n",
    "\n",
    "# Compute the sampling UQ plots\n",
    "superpix_sizes = [32, 16, 8, 4, 1]\n",
    "\n",
    "# Sampling alg params\n",
    "frac_delta = 0.98\n",
    "frac_burnin = 0.1\n",
    "n_samples = np.int64(5e4)\n",
    "thinning = np.int64(1e1)\n",
    "maxit = np.int64(n_samples * thinning * (1.0 + frac_burnin))\n",
    "# SKROCK params\n",
    "nStages = 10\n",
    "eta = 0.05\n",
    "dt_perc = 0.99\n",
    "\n",
    "# Plot parameters\n",
    "cmap = \"cubehelix\"\n",
    "nLags = 100\n",
    "\n",
    "\n",
    "# Img name list\n",
    "img_name_list = [\"W28\"]  # ['M31', 'W28', 'CYN', '3c288']\n",
    "# Input noise level\n",
    "input_snr = 30.0\n",
    "\n",
    "\n",
    "save_fig_vals = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold:  0.0005199805892932551\n",
      "Running Base Forward Backward\n",
      "[Forward Backward] 0 out of 15000 iterations, tol = 5.24e-01\n",
      "[Forward Backward] converged in 533 iterations\n",
      "Dirty\n",
      "(PSNR: 32.25,\n",
      " SNR: 3.39, SSIM: 0.58)\n",
      "Reconstruction\n",
      "(PSNR: 51.9,\n",
      " SNR: 23.04, SSIM: 0.99)\n",
      "Residual (x - x^hat)\n",
      "(PSNR: 28.94,\n",
      " SNR: 0.09, SSIM: 0.92)\n",
      "Calculating credible interval for superpxiel:  (256, 256)\n",
      "[Bisection Method] There is no root in this range.\n",
      "[Bisection Method] There is no root in this range.\n",
      "[Bisection Method] There is no root in this range.\n",
      "[Bisection Method] There is no root in this range.\n",
      "[Bisection Method] There is no root in this range.\n",
      "[Bisection Method] There is no root in this range.\n",
      "[Bisection Method] There is no root in this range.\n",
      "[Bisection Method] There is no root in this range.\n",
      "Calculating credible interval for superpxiel:  (256, 256)\n",
      "[Bisection Method] There is no root in this range.\n",
      "[Bisection Method] There is no root in this range.\n",
      "[Bisection Method] There is no root in this range.\n",
      "[Bisection Method] There is no root in this range.\n",
      "[Bisection Method] There is no root in this range.\n",
      "[Bisection Method] There is no root in this range.\n",
      "[Bisection Method] There is no root in this range.\n",
      "[Bisection Method] There is no root in this range.\n",
      "[Bisection Method] There is no root in this range.\n",
      "[Bisection Method] There is no root in this range.\n",
      "f(x_map):  1073.3816412074607 \n",
      "g(x_map):  27312.814016682878 \n",
      "tau_alpha*np.sqrt(N):  2445.577521189034 \n",
      "N:  65536\n",
      "tau_alpha:  9.553037192144664\n",
      "gamma_alpha:  96367.77317907938\n"
     ]
    }
   ],
   "source": [
    "for img_name in img_name_list:\n",
    "    optim_iters = []\n",
    "    lci_uq_iters_arr = []\n",
    "\n",
    "    # %%\n",
    "    # Load image and mask\n",
    "    img, mat_mask = qai.helpers.load_imgs(img_name, repo_dir)\n",
    "\n",
    "    # Aliases\n",
    "    x = img\n",
    "    ground_truth = img\n",
    "\n",
    "    torch_img = torch.tensor(np.copy(img), dtype=myType, device=device).reshape(\n",
    "        (1, 1) + img.shape\n",
    "    )\n",
    "\n",
    "    phi = qai.operators.MaskedFourier_torch(\n",
    "        shape=img.shape, ratio=0.5, mask=mat_mask, norm=\"ortho\", device=device\n",
    "    )\n",
    "\n",
    "    y = phi.dir_op(torch_img).detach().cpu().squeeze().numpy()\n",
    "\n",
    "    # Define X Cai noise level\n",
    "    eff_sigma = qai.helpers.compute_complex_sigma_noise(y, input_snr)\n",
    "    sigma = eff_sigma * np.sqrt(2)\n",
    "\n",
    "    # Generate noise\n",
    "    rng = np.random.default_rng(seed=0)\n",
    "    n_re = rng.normal(0, eff_sigma, y[y != 0].shape)\n",
    "    n_im = rng.normal(0, eff_sigma, y[y != 0].shape)\n",
    "    # Add noise\n",
    "    y[y != 0] += n_re + 1.0j * n_im\n",
    "\n",
    "    # Observation\n",
    "    torch_y = torch.tensor(np.copy(y), device=device, dtype=myComplexType).reshape(\n",
    "        (1,) + img.shape\n",
    "    )\n",
    "    x_init = torch.abs(phi.adj_op(torch_y))\n",
    "\n",
    "    # %%\n",
    "    # Define the likelihood\n",
    "    likelihood = qai.operators.L2Norm_torch(\n",
    "        sigma=sigma,\n",
    "        data=torch_y,\n",
    "        Phi=phi,\n",
    "    )\n",
    "    # Lipschitz constant computed automatically by likelihood, stored in likelihood.beta\n",
    "\n",
    "    # Define real prox\n",
    "    cvx_set_prox_op = qai.operators.RealProx_torch()\n",
    "\n",
    "    # %%\n",
    "\n",
    "    for it_1 in range(len(reg_params)):\n",
    "        # Prior parameters\n",
    "        reg_param = reg_params[it_1]\n",
    "\n",
    "        # Define the wavelet dict\n",
    "        # Define the l1 norm with dict psi\n",
    "        psi = qai.operators.DictionaryWv_torch(wavs_list, levels)\n",
    "        reg_prox_op = qai.operators.L1Norm_torch(1.0, psi, op_to_coeffs=True)\n",
    "        reg_prox_op.gamma = reg_param\n",
    "\n",
    "        # Compute stepsize\n",
    "        alpha = 0.98 / likelihood.beta\n",
    "\n",
    "        # Effective threshold\n",
    "        print(\"Threshold: \", reg_prox_op.gamma * alpha)\n",
    "\n",
    "        # Run the optimisation\n",
    "        x_hat, diagnostics = qai.optim.FISTA_torch(\n",
    "            x_init,\n",
    "            options=options,\n",
    "            likelihood=likelihood,\n",
    "            cvx_set_prox_op=cvx_set_prox_op,\n",
    "            reg_prox_op=reg_prox_op,\n",
    "            alpha=alpha,\n",
    "            tau=alpha,\n",
    "            viewer=None,\n",
    "        )\n",
    "\n",
    "        # %%\n",
    "        np_x_init = to_numpy(x_init)\n",
    "        np_x = np.copy(x)\n",
    "        np_x_hat = to_numpy(x_hat)\n",
    "\n",
    "        # %%\n",
    "        images = [np_x, np_x_init, np_x_hat, np_x - np.abs(np_x_hat)]\n",
    "        labels = [\"Truth\", \"Dirty\", \"Reconstruction\", \"Residual (x - x^hat)\"]\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(24, 6), dpi=200)\n",
    "        for i in range(4):\n",
    "            im = axs[i].imshow(\n",
    "                images[i],\n",
    "                cmap=\"cubehelix\",\n",
    "                vmax=np.nanmax(images[i]),\n",
    "                vmin=np.nanmin(images[i]),\n",
    "            )\n",
    "            divider = make_axes_locatable(axs[i])\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            fig.colorbar(im, cax=cax, orientation=\"vertical\")\n",
    "            if i > 0:\n",
    "                stats_str = \"\\n(PSNR: {},\\n SNR: {}, SSIM: {})\".format(\n",
    "                    round(\n",
    "                        psnr(\n",
    "                            ground_truth,\n",
    "                            images[i],\n",
    "                            data_range=ground_truth.max() - ground_truth.min(),\n",
    "                        ),\n",
    "                        2,\n",
    "                    ),\n",
    "                    round(qai.utils.eval_snr(x, images[i]), 2),\n",
    "                    round(\n",
    "                        ssim(\n",
    "                            ground_truth,\n",
    "                            images[i],\n",
    "                            data_range=ground_truth.max() - ground_truth.min(),\n",
    "                        ),\n",
    "                        2,\n",
    "                    ),\n",
    "                )\n",
    "                labels[i] += stats_str\n",
    "                print(labels[i])\n",
    "            axs[i].set_title(labels[i], fontsize=16)\n",
    "            axs[i].axis(\"off\")\n",
    "        # plt.savefig('{:s}{:s}_SKROCK_wavelets_reg_param_{:.1e}_optim_MAP.pdf'.format(savefig_dir, img_name, reg_param))\n",
    "        plt.close()\n",
    "\n",
    "        ### MAP-based UQ\n",
    "\n",
    "        # Define prior potential\n",
    "        fun_prior = lambda _x: reg_prox_op._fun_coeffs(reg_prox_op.dir_op(_x))\n",
    "        # Define posterior potential\n",
    "        loss_fun_torch = lambda _x: likelihood.fun(_x) + fun_prior(_x)\n",
    "        # Numpy version of the posterior potential\n",
    "        loss_fun_np = (\n",
    "            lambda _x: likelihood.fun(qai.utils.to_tensor(_x, dtype=myType)).item()\n",
    "            + fun_prior(qai.utils.to_tensor(_x, dtype=myType)).item()\n",
    "        )\n",
    "\n",
    "        # Compute HPD region bound\n",
    "        N = np_x_hat.size\n",
    "        tau_alpha = np.sqrt(16 * np.log(3 / alpha_prob))\n",
    "        gamma_alpha = loss_fun_torch(x_hat).item() + tau_alpha * np.sqrt(N) + N\n",
    "\n",
    "        # Compute the LCI\n",
    "        error_p_arr = []\n",
    "        error_m_arr = []\n",
    "        mean_img_arr = []\n",
    "        computing_time = []\n",
    "\n",
    "        x_init_np = qai.utils.to_numpy(x_init)\n",
    "\n",
    "        # Compute ground truth block\n",
    "        gt_mean_img_arr = []\n",
    "        for superpix_size in superpix_MAP_sizes:\n",
    "            mean_image = ski.measure.block_reduce(\n",
    "                np.copy(img), block_size=(superpix_size, superpix_size), func=np.mean\n",
    "            )\n",
    "            gt_mean_img_arr.append(mean_image)\n",
    "\n",
    "        # Define prefix\n",
    "        save_MAP_prefix = \"{:s}_wavelets_UQ_MAP_reg_param_{:.1e}\".format(\n",
    "            img_name, reg_param\n",
    "        )\n",
    "\n",
    "        for it_pixs, superpix_size in enumerate(superpix_MAP_sizes):\n",
    "            pr_time_1 = time.process_time()\n",
    "            wall_time_1 = time.time()\n",
    "\n",
    "            (\n",
    "                error_p,\n",
    "                error_m,\n",
    "                mean,\n",
    "                lci_iters_cumul,\n",
    "            ) = qai.map_uncertainty.create_local_credible_interval(\n",
    "                x_sol=np_x_hat,\n",
    "                region_size=superpix_size,\n",
    "                function=loss_fun_np,\n",
    "                bound=gamma_alpha,\n",
    "                iters=LCI_iters,\n",
    "                tol=LCI_tol,\n",
    "                bottom=LCI_bottom,\n",
    "                top=LCI_top,\n",
    "                return_iters=True,\n",
    "            )\n",
    "            pr_time_2 = time.process_time()\n",
    "            wall_time_2 = time.time()\n",
    "\n",
    "            # Save iteration number\n",
    "            lci_uq_iters_arr.append(lci_iters_cumul)\n",
    "\n",
    "            # Add values to array to save it later\n",
    "            error_p_arr.append(np.copy(error_p))\n",
    "            error_m_arr.append(np.copy(error_m))\n",
    "            mean_img_arr.append(np.copy(mean))\n",
    "            computing_time.append((pr_time_2 - pr_time_1, wall_time_2 - wall_time_1))\n",
    "            # Clip plot values\n",
    "            error_length = qai.utils.clip_matrix(\n",
    "                np.copy(error_p), clip_low_val, clip_high_val\n",
    "            ) - qai.utils.clip_matrix(np.copy(error_m), clip_low_val, clip_high_val)\n",
    "            # Recover the ground truth mean\n",
    "            gt_mean = gt_mean_img_arr[it_pixs]\n",
    "\n",
    "            vmin = np.min((gt_mean, mean, error_length))\n",
    "            vmax = np.max((gt_mean, mean, error_length))\n",
    "\n",
    "            # Plot UQ\n",
    "            fig = plt.figure(figsize=(24, 5))\n",
    "\n",
    "            plt.subplot(141)\n",
    "            ax = plt.gca()\n",
    "            ax.set_title(\"MAP estimation,\\n superpix = {:d}\".format(superpix_size))\n",
    "            im = ax.imshow(mean, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            fig.colorbar(im, cax=cax, orientation=\"vertical\")\n",
    "            ax.set_yticks([])\n",
    "            ax.set_xticks([])\n",
    "\n",
    "            plt.subplot(142)\n",
    "            ax = plt.gca()\n",
    "            ax.set_title(\n",
    "                \"Residual (GT - MAP),\\n RMSE = {:.3e}\".format(\n",
    "                    np.sqrt(np.sum((gt_mean - mean) ** 2))\n",
    "                )\n",
    "            )\n",
    "            im = ax.imshow(gt_mean - mean, cmap=cmap)\n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            fig.colorbar(im, cax=cax, orientation=\"vertical\")\n",
    "            ax.set_yticks([])\n",
    "            ax.set_xticks([])\n",
    "\n",
    "            plt.subplot(143)\n",
    "            ax = plt.gca()\n",
    "            ax.set_title(\n",
    "                \"LCI (max={:.5f})\\n (<LCI>={:.5f})\".format(\n",
    "                    np.max(error_length), np.mean(error_length)\n",
    "                )\n",
    "            )\n",
    "            im = ax.imshow(error_length, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            fig.colorbar(im, cax=cax, orientation=\"vertical\")\n",
    "            ax.set_yticks([])\n",
    "            ax.set_xticks([])\n",
    "\n",
    "            plt.subplot(144)\n",
    "            ax = plt.gca()\n",
    "            ax.set_title(\"LCI - min(LCI)\")\n",
    "            im = ax.imshow(\n",
    "                error_length - np.min(error_length), cmap=cmap, vmin=vmin, vmax=vmax\n",
    "            )\n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            fig.colorbar(im, cax=cax, orientation=\"vertical\")\n",
    "            ax.set_yticks([])\n",
    "            ax.set_xticks([])\n",
    "\n",
    "            # plt.savefig(\n",
    "            #     savefig_dir+save_MAP_prefix+'_UQ-MAP_pixel_size_{:d}.pdf'.format(superpix_size)\n",
    "            # )\n",
    "            plt.close()\n",
    "\n",
    "        print(\n",
    "            \"f(x_map): \",\n",
    "            likelihood.fun(x_hat).item(),\n",
    "            \"\\ng(x_map): \",\n",
    "            fun_prior(x_hat).item(),\n",
    "            \"\\ntau_alpha*np.sqrt(N): \",\n",
    "            tau_alpha * np.sqrt(N),\n",
    "            \"\\nN: \",\n",
    "            N,\n",
    "        )\n",
    "        print(\"tau_alpha: \", tau_alpha)\n",
    "        print(\"gamma_alpha: \", gamma_alpha.item())\n",
    "        #\n",
    "        opt_params = {\n",
    "            \"wav\": wavs_list,\n",
    "            \"levels\": levels,\n",
    "            \"reg_param\": reg_param,\n",
    "            \"sigma_noise\": sigma,\n",
    "            \"opt_tol\": options[\"tol\"],\n",
    "            \"opt_max_iter\": options[\"iter\"],\n",
    "        }\n",
    "        hpd_results = {\n",
    "            \"alpha\": alpha_prob,\n",
    "            \"gamma_alpha\": gamma_alpha,\n",
    "            \"f_xmap\": likelihood.fun(x_hat).item(),\n",
    "            \"g_xmap\": fun_prior(x_hat).item(),\n",
    "            \"h_alpha_N\": tau_alpha * np.sqrt(N) + N,\n",
    "        }\n",
    "        LCI_params = {\n",
    "            \"iters\": LCI_iters,\n",
    "            \"tol\": LCI_tol,\n",
    "            \"bottom\": LCI_bottom,\n",
    "            \"top\": LCI_top,\n",
    "            \"top\": LCI_top,\n",
    "            \"clip_low_val\": clip_low_val,\n",
    "            \"clip_high_val\": clip_high_val,\n",
    "        }\n",
    "        save_map_vars = {\n",
    "            \"x_ground_truth\": img,\n",
    "            \"x_map\": np_x_hat,\n",
    "            \"x_init\": np_x_init,\n",
    "            \"opt_params\": opt_params,\n",
    "            \"hpd_results\": hpd_results,\n",
    "            \"error_p_arr\": error_p_arr,\n",
    "            \"error_m_arr\": error_m_arr,\n",
    "            \"mean_img_arr\": mean_img_arr,\n",
    "            \"gt_mean_img_arr\": gt_mean_img_arr,\n",
    "            \"computing_time\": computing_time,\n",
    "            \"superpix_sizes\": superpix_MAP_sizes,\n",
    "            \"LCI_params\": LCI_params,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number for W28\n",
      "LCI iterations 16x16 super pixe:  21188\n",
      "LCI iterations 8x8 super pixe:  81540\n"
     ]
    }
   ],
   "source": [
    "print(\"Iteration number for W28\")\n",
    "\n",
    "# print('Optimisation iterations: ', optim_iters[0])\n",
    "print(\"LCI iterations 16x16 super pixe: \", lci_uq_iters_arr[0])\n",
    "print(\"LCI iterations 8x8 super pixe: \", lci_uq_iters_arr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convex_uq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "2bb75ebd6ceb1eff2ce987e124c91bc6f99e62fd1930d98a82dc138614104eef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
