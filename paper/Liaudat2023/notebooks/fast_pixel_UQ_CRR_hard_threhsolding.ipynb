{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import time as time\n",
    "\n",
    "import torch\n",
    "\n",
    "M1 = False\n",
    "\n",
    "if M1:\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "else:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(torch.cuda.is_available())\n",
    "        print(torch.cuda.device_count())\n",
    "        print(torch.cuda.current_device())\n",
    "        print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from torchmetrics.functional import structural_similarity_index_measure\n",
    "from torchmetrics.functional import peak_signal_noise_ratio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.ticker as tick\n",
    "\n",
    "import scipy.io as sio\n",
    "from astropy.io import fits\n",
    "import skimage as ski\n",
    "\n",
    "import quantifai as qai\n",
    "from quantifai.utils import to_numpy, to_tensor\n",
    "from convex_reg import utils as utils_cvx_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and parameters\n",
    "repo_dir = \"./../../..\"\n",
    "\n",
    "CRR_save_dir = (\n",
    "    \"/disk/xray0/tl3/outputs/large-scale-UQ/def_UQ_results/v2/CRR/new_pix_UQ_hard/\"\n",
    ")\n",
    "load_var_dir = \"/disk/xray99/tl3/proj-convex-UQ/outputs/new_UQ_results/CRR/vars/\"\n",
    "\n",
    "cmap = \"cubehelix\"\n",
    "cbar_font_size = 18\n",
    "\n",
    "\n",
    "img_name_arr = [\n",
    "    \"CYN\",\n",
    "    \"M31\",\n",
    "    \"3c288\",\n",
    "    \"W28\",\n",
    "]\n",
    "vmin_log_arr = [\n",
    "    -3.0,\n",
    "    -2.0,\n",
    "    -2.0,\n",
    "    -2.0,\n",
    "]\n",
    "\n",
    "computing_time_arr = []\n",
    "\n",
    "options = {\"tol\": 1e-5, \"iter\": 15000, \"update_iter\": 4999, \"record_iters\": False}\n",
    "\n",
    "# CRR load parameters\n",
    "sigma_training = 5\n",
    "t_model = 5\n",
    "CRR_dir_name = \"./../../../trained_models/\"\n",
    "# CRR parameters\n",
    "reg_param = 5e4\n",
    "mu = 20\n",
    "\n",
    "# Define my torch types (CRR requires torch.float32)\n",
    "myType = torch.float32\n",
    "myComplexType = torch.complex64\n",
    "\n",
    "# Parameters\n",
    "alpha_prob = 0.01\n",
    "\n",
    "# Define the wavelet parameters for UQ maps\n",
    "wavs_list = [\"db8\"]\n",
    "levels = 4\n",
    "# Parameters for UQ map\n",
    "start_interval = [0, 10]\n",
    "iters = 5e2\n",
    "tol = 1e-2\n",
    "\n",
    "model_prefix = \"-CRR\"\n",
    "input_snr = 30.0\n",
    "\n",
    "\n",
    "save_fig_vals = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in range(len(img_name_arr)):\n",
    "    # Set paths\n",
    "    if model_prefix == \"-CRR\":\n",
    "        img_name = img_name_arr[it]\n",
    "        vmin_log = vmin_log_arr[it]\n",
    "        save_dir = CRR_save_dir\n",
    "        save_var_dir = load_var_dir\n",
    "\n",
    "    computing_time_arr = []\n",
    "    n_iters_uq = []\n",
    "\n",
    "    # Load image and mask\n",
    "    img, mat_mask = qai.helpers.load_imgs(img_name, repo_dir)\n",
    "    # Aliases\n",
    "    x = img\n",
    "    ground_truth = img\n",
    "    # Convert Torch\n",
    "    torch_img = torch.tensor(np.copy(img), dtype=myType, device=device).reshape(\n",
    "        (1, 1) + img.shape\n",
    "    )\n",
    "    # Init Fourier masl op\n",
    "    phi = qai.operators.MaskedFourier_torch(\n",
    "        shape=img.shape, ratio=0.5, mask=mat_mask, norm=\"ortho\", device=device\n",
    "    )\n",
    "    y = phi.dir_op(torch_img).detach().cpu().squeeze().numpy()\n",
    "\n",
    "    # Define X Cai noise level\n",
    "    eff_sigma = qai.helpers.compute_complex_sigma_noise(y, input_snr)\n",
    "    sigma = eff_sigma * np.sqrt(2)\n",
    "\n",
    "    # Generate noise\n",
    "    rng = np.random.default_rng(seed=0)\n",
    "    n_re = rng.normal(0, eff_sigma, y[y != 0].shape)\n",
    "    n_im = rng.normal(0, eff_sigma, y[y != 0].shape)\n",
    "    # Add noise\n",
    "    y[y != 0] += n_re + 1.0j * n_im\n",
    "\n",
    "    # Observation\n",
    "    torch_y = torch.tensor(np.copy(y), device=device, dtype=myComplexType).reshape(\n",
    "        (1,) + img.shape\n",
    "    )\n",
    "    x_init = torch.abs(phi.adj_op(torch_y))\n",
    "    # Define the likelihood\n",
    "    likelihood = qai.operators.L2Norm_torch(\n",
    "        sigma=sigma,\n",
    "        data=torch_y,\n",
    "        Phi=phi,\n",
    "    )\n",
    "    # Lipschitz constant computed automatically by likelihood, stored in likelihood.beta\n",
    "    # Define real prox\n",
    "    prox_op = qai.operators.RealProx_torch()\n",
    "\n",
    "    # Load CRR model\n",
    "    torch.set_grad_enabled(False)\n",
    "    torch.set_num_threads(4)\n",
    "\n",
    "    exp_name = f\"Sigma_{sigma_training}_t_{t_model}/\"\n",
    "    CRR_model = utils_cvx_reg.load_model(\n",
    "        CRR_dir_name + exp_name, \"cuda:0\", device_type=\"gpu\"\n",
    "    )\n",
    "\n",
    "    print(f\"Numbers of parameters before prunning: {CRR_model.num_params}\")\n",
    "    CRR_model.prune()\n",
    "    print(f\"Numbers of parameters after prunning: {CRR_model.num_params}\")\n",
    "\n",
    "    # L_CRR = CRR_model.L.detach().cpu().squeeze().numpy()\n",
    "    # print(f\"Lipschitz bound {L_CRR:.3f}\")\n",
    "\n",
    "    # [not required] intialize the eigen vector of dimension (size, size) associated to the largest eigen value\n",
    "    CRR_model.initializeEigen(size=100)\n",
    "    # compute bound via a power iteration which couples the activations and the convolutions\n",
    "    CRR_model.precise_lipschitz_bound(n_iter=100)\n",
    "    # the bound is stored in the model\n",
    "    L_CRR = CRR_model.L.data.item()\n",
    "    print(f\"Lipschitz bound {L_CRR:.3f}\")\n",
    "\n",
    "    ## Compute MAP solution\n",
    "    # Prior parameters\n",
    "    lmbd = reg_param\n",
    "\n",
    "    # Compute stepsize\n",
    "    alpha = 0.98 / (likelihood.beta + mu * lmbd * L_CRR)\n",
    "\n",
    "    x_hat = qai.optim.FISTA_CRR_torch(\n",
    "        x_init=x_init,\n",
    "        options=options,\n",
    "        likelihood=likelihood,\n",
    "        prox_op=prox_op,\n",
    "        CRR_model=CRR_model,\n",
    "        alpha=alpha,\n",
    "        lmbd=lmbd,\n",
    "        mu=mu,\n",
    "    )\n",
    "\n",
    "    # Save MAP\n",
    "    np_x_hat = to_numpy(x_hat)\n",
    "    np_x = np.copy(x)\n",
    "    # Evaluate performance\n",
    "    print(img_name, \" PSNR: \", psnr(np_x, np_x_hat, data_range=np_x.max() - np_x.min()))\n",
    "    print(img_name, \" SNR: \", qai.utils.eval_snr(x, np_x_hat))\n",
    "\n",
    "    # Function handle for the potential\n",
    "    def _fun(_x, CRR_model, mu, lmbd):\n",
    "        return (lmbd / mu) * CRR_model.cost(mu * _x) + likelihood.fun(_x)\n",
    "\n",
    "    # Evaluation of the potential\n",
    "    fun = partial(_fun, CRR_model=CRR_model, mu=mu, lmbd=lmbd)\n",
    "    # Evaluation of the potential in numpy\n",
    "    fun_np = lambda _x: fun(qai.utils.to_tensor(_x, dtype=myType)).item()\n",
    "\n",
    "    # Compute HPD region bound\n",
    "    N = np_x_hat.size\n",
    "    tau_alpha = np.sqrt(16 * np.log(3 / alpha_prob))\n",
    "    gamma_alpha = fun(x_hat).item() + tau_alpha * np.sqrt(N) + N\n",
    "\n",
    "    # Define the wavelet dict\n",
    "    # Define the l1 norm with dict psi\n",
    "    Psi = qai.operators.DictionaryWv_torch(wavs_list, levels)\n",
    "    oper2wavelet = qai.operators.Operation2WaveletCoeffs_torch(Psi=Psi)\n",
    "\n",
    "    # Clone MAP estimation and cast type for wavelet operations\n",
    "    torch_map = torch.clone(x_hat).to(torch.float64)\n",
    "    torch_x = to_tensor(np_x).to(torch.float64)\n",
    "\n",
    "    def _potential_to_bisect(thresh, fun_np, oper2wavelet, torch_map):\n",
    "        thresh_img = oper2wavelet.full_op_threshold_img(\n",
    "            torch_map, thresh, thresh_type=\"hard\"\n",
    "        )\n",
    "\n",
    "        return gamma_alpha - fun_np(thresh_img)\n",
    "\n",
    "    # Evaluation of the potential\n",
    "    potential_to_bisect = partial(\n",
    "        _potential_to_bisect,\n",
    "        fun_np=fun_np,\n",
    "        oper2wavelet=oper2wavelet,\n",
    "        torch_map=torch_map,\n",
    "    )\n",
    "\n",
    "    wall_time_1 = time.time()\n",
    "\n",
    "    selected_thresh, bisec_iters = qai.map_uncertainty.bisection_method(\n",
    "        potential_to_bisect, start_interval, iters, tol, return_iters=True\n",
    "    )\n",
    "    select_thresh_img = oper2wavelet.full_op_threshold_img(torch_map, selected_thresh)\n",
    "    wall_time_2 = time.time()\n",
    "    # Save iteration number for pixel UQ\n",
    "    n_iters_uq.append(bisec_iters)\n",
    "    print(\"Pixel UQ required \", bisec_iters, \" iterations to converge.\")\n",
    "\n",
    "    # Save time\n",
    "    computing_time_arr.append(wall_time_2 - wall_time_1)\n",
    "\n",
    "    print(\"selected_thresh: \", selected_thresh)\n",
    "    print(\"gamma_alpha: \", gamma_alpha)\n",
    "    print(\"MAP image: \", fun_np(torch_map.squeeze()))\n",
    "    print(\"thresholded image: \", fun_np(select_thresh_img))\n",
    "\n",
    "    # Plot MAP\n",
    "    fig = plt.figure(figsize=(5, 5), dpi=200)\n",
    "    axs = plt.gca()\n",
    "    im_log = np.log10(np.abs(np_x_hat))\n",
    "    plt_im = axs.imshow(im_log, cmap=cmap, vmin=vmin_log, vmax=0)\n",
    "    divider = make_axes_locatable(axs)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = fig.colorbar(plt_im, cax=cax)\n",
    "    cbar.ax.yaxis.set_major_formatter(tick.FormatStrFormatter(\"%.2f\"))\n",
    "    cbar.ax.tick_params(labelsize=cbar_font_size)\n",
    "    axs.set_yticks([])\n",
    "    axs.set_xticks([])\n",
    "    plt.tight_layout()\n",
    "    if save_fig_vals:\n",
    "        plt.savefig(\n",
    "            \"{:s}{:s}{:s}{:s}\".format(\n",
    "                save_dir, img_name, model_prefix, \"-newPixelUQ-MAP.pdf\"\n",
    "            ),\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=200,\n",
    "        )\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Thresholded image\n",
    "    fig = plt.figure(figsize=(5, 5), dpi=200)\n",
    "    axs = plt.gca()\n",
    "    im_log = np.log10(np.abs(to_numpy(select_thresh_img)))\n",
    "    plt_im = axs.imshow(im_log, cmap=cmap, vmin=vmin_log, vmax=0)\n",
    "    divider = make_axes_locatable(axs)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = fig.colorbar(plt_im, cax=cax)\n",
    "    cbar.ax.yaxis.set_major_formatter(tick.FormatStrFormatter(\"%.2f\"))\n",
    "    cbar.ax.tick_params(labelsize=cbar_font_size)\n",
    "    axs.set_yticks([])\n",
    "    axs.set_xticks([])\n",
    "    plt.tight_layout()\n",
    "    if save_fig_vals:\n",
    "        plt.savefig(\n",
    "            \"{:s}{:s}{:s}{:s}\".format(\n",
    "                save_dir, img_name, model_prefix, \"-newPixelUQ-ThresholdedImage.pdf\"\n",
    "            ),\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=200,\n",
    "        )\n",
    "    plt.show()\n",
    "\n",
    "    # Plot MAP - Thresholded error\n",
    "    fig = plt.figure(figsize=(5, 5), dpi=200)\n",
    "    axs = plt.gca()\n",
    "    im_log = np.log10(np.abs(to_numpy(torch_map - select_thresh_img)))\n",
    "    plt_im = axs.imshow(im_log, cmap=cmap, vmin=vmin_log - 2, vmax=0)\n",
    "    divider = make_axes_locatable(axs)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = fig.colorbar(plt_im, cax=cax)\n",
    "    cbar.ax.yaxis.set_major_formatter(tick.FormatStrFormatter(\"%.2f\"))\n",
    "    cbar.ax.tick_params(labelsize=cbar_font_size)\n",
    "    axs.set_yticks([])\n",
    "    axs.set_xticks([])\n",
    "    plt.tight_layout()\n",
    "    if save_fig_vals:\n",
    "        plt.savefig(\n",
    "            \"{:s}{:s}{:s}{:s}\".format(\n",
    "                save_dir,\n",
    "                img_name,\n",
    "                model_prefix,\n",
    "                \"-newPixelUQ-MAP_thresholded_error.pdf\",\n",
    "            ),\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=200,\n",
    "        )\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Ground truth - MAP\n",
    "    fig = plt.figure(figsize=(5, 5), dpi=200)\n",
    "    axs = plt.gca()\n",
    "    im_log = np.log10(np.abs(np_x - np_x_hat))\n",
    "    plt_im = axs.imshow(im_log, cmap=cmap, vmin=vmin_log - 2, vmax=0)\n",
    "    divider = make_axes_locatable(axs)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = fig.colorbar(plt_im, cax=cax)\n",
    "    cbar.ax.yaxis.set_major_formatter(tick.FormatStrFormatter(\"%.2f\"))\n",
    "    cbar.ax.tick_params(labelsize=cbar_font_size)\n",
    "    axs.set_yticks([])\n",
    "    axs.set_xticks([])\n",
    "    plt.tight_layout()\n",
    "    if save_fig_vals:\n",
    "        plt.savefig(\n",
    "            \"{:s}{:s}{:s}{:s}\".format(\n",
    "                save_dir, img_name, model_prefix, \"-newPixelUQ-GT_MAP_error.pdf\"\n",
    "            ),\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=200,\n",
    "        )\n",
    "    plt.show()\n",
    "\n",
    "    modif_img_list = []\n",
    "    GT_modif_img_list = []\n",
    "    SNR_at_lvl_list = []\n",
    "    SNR_at_lvl_map_vs_GT_list = []\n",
    "\n",
    "    for modif_level in range(levels + 1):\n",
    "        op = lambda x1, x2: x2\n",
    "\n",
    "        modif_img = oper2wavelet.full_op_two_img(\n",
    "            torch.clone(torch_map),\n",
    "            torch.clone(select_thresh_img),\n",
    "            op,\n",
    "            level=modif_level,\n",
    "        )\n",
    "        GT_modif_img = oper2wavelet.full_op_two_img(\n",
    "            torch.clone(torch_x), torch.clone(torch_map), op, level=modif_level\n",
    "        )\n",
    "        print(\n",
    "            \"SNR (thresh vs MAP) at lvl {:d}: {:f}\".format(\n",
    "                modif_level,\n",
    "                qai.utils.eval_snr(to_numpy(torch_map), to_numpy(modif_img)),\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"SNR (MAP vs GT) at lvl {:d}: {:f}\".format(\n",
    "                modif_level,\n",
    "                qai.utils.eval_snr(to_numpy(torch_x), to_numpy(GT_modif_img)),\n",
    "            )\n",
    "        )\n",
    "        modif_img_list.append(to_numpy(modif_img))\n",
    "        GT_modif_img_list.append(to_numpy(GT_modif_img))\n",
    "        SNR_at_lvl_list.append(\n",
    "            qai.utils.eval_snr(to_numpy(torch_map), to_numpy(modif_img))\n",
    "        )\n",
    "        SNR_at_lvl_map_vs_GT_list.append(\n",
    "            qai.utils.eval_snr(to_numpy(torch_x), to_numpy(GT_modif_img))\n",
    "        )\n",
    "\n",
    "        # Plot MAP - Thresholded error\n",
    "        fig = plt.figure(figsize=(5, 5), dpi=200)\n",
    "        axs = plt.gca()\n",
    "        im_log = np.log10(np.abs(to_numpy(torch_map - modif_img)))\n",
    "        plt_im = axs.imshow(im_log, cmap=cmap, vmin=vmin_log - 2, vmax=0)\n",
    "        divider = make_axes_locatable(axs)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        cbar = fig.colorbar(plt_im, cax=cax)\n",
    "        cbar.ax.yaxis.set_major_formatter(tick.FormatStrFormatter(\"%.2f\"))\n",
    "        cbar.ax.tick_params(labelsize=cbar_font_size)\n",
    "        axs.set_yticks([])\n",
    "        axs.set_xticks([])\n",
    "        plt.tight_layout()\n",
    "        if save_fig_vals:\n",
    "            plt.savefig(\n",
    "                \"{:s}{:s}{:s}{:s}{:d}{:s}\".format(\n",
    "                    save_dir,\n",
    "                    img_name,\n",
    "                    model_prefix,\n",
    "                    \"-newPixelUQ-MAP_thresholded_error_level_\",\n",
    "                    modif_level,\n",
    "                    \".pdf\",\n",
    "                ),\n",
    "                bbox_inches=\"tight\",\n",
    "                dpi=200,\n",
    "            )\n",
    "        plt.show()\n",
    "\n",
    "        # Plot GT - MAP error\n",
    "        fig = plt.figure(figsize=(5, 5), dpi=200)\n",
    "        axs = plt.gca()\n",
    "        im_log = np.log10(np.abs(np_x - to_numpy(GT_modif_img)))\n",
    "        plt_im = axs.imshow(im_log, cmap=cmap, vmin=vmin_log - 2, vmax=0)\n",
    "        divider = make_axes_locatable(axs)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        cbar = fig.colorbar(plt_im, cax=cax)\n",
    "        cbar.ax.yaxis.set_major_formatter(tick.FormatStrFormatter(\"%.2f\"))\n",
    "        cbar.ax.tick_params(labelsize=cbar_font_size)\n",
    "        axs.set_yticks([])\n",
    "        axs.set_xticks([])\n",
    "        plt.tight_layout()\n",
    "        if save_fig_vals:\n",
    "            plt.savefig(\n",
    "                \"{:s}{:s}{:s}{:s}{:d}{:s}\".format(\n",
    "                    save_dir,\n",
    "                    img_name,\n",
    "                    model_prefix,\n",
    "                    \"-newPixelUQ-GT_MAP_error_level_\",\n",
    "                    modif_level,\n",
    "                    \".pdf\",\n",
    "                ),\n",
    "                bbox_inches=\"tight\",\n",
    "                dpi=200,\n",
    "            )\n",
    "        plt.show()\n",
    "\n",
    "    config_dict = {\n",
    "        \"sigma_training\": sigma_training,\n",
    "        \"t_model\": t_model,\n",
    "        \"reg_param\": reg_param,\n",
    "        \"mu\": mu,\n",
    "        \"alpha_prob\": alpha_prob,\n",
    "        \"wavs_list\": wavs_list,\n",
    "        \"levels\": levels,\n",
    "        \"start_interval\": start_interval,\n",
    "        \"iters\": iters,\n",
    "        \"tol\": tol,\n",
    "        \"optim_options\": options,\n",
    "    }\n",
    "    save_dict = {\n",
    "        \"gt\": np_x,\n",
    "        \"map\": np_x_hat,\n",
    "        \"thresholded_img\": to_numpy(select_thresh_img),\n",
    "        \"map_thresh_error_at_level\": np.array(modif_img_list),\n",
    "        \"gt_map_error_at_level\": np.array(GT_modif_img_list),\n",
    "        \"SNR_at_level\": np.array(SNR_at_lvl_list),\n",
    "        \"SNR_at_lvl_map_vs_GT\": np.array(SNR_at_lvl_map_vs_GT_list),\n",
    "        \"computing_time_arr\": computing_time_arr,\n",
    "        \"n_iters_uq\": n_iters_uq,\n",
    "        \"config_dict\": config_dict,\n",
    "    }\n",
    "\n",
    "    # We will overwrite the dict with new results\n",
    "    try:\n",
    "        saving_var_path = \"{:s}{:s}{:s}{:s}\".format(\n",
    "            save_var_dir,\n",
    "            img_name,\n",
    "            model_prefix,\n",
    "            \"-new_pixel_UQ_vars.npy\",\n",
    "        )\n",
    "        if save_fig_vals:\n",
    "            if os.path.isfile(saving_var_path):\n",
    "                os.remove(saving_var_path)\n",
    "            np.save(saving_var_path, save_dict, allow_pickle=True)\n",
    "    except Exception as e:\n",
    "        print(\"Could not save vairables. Exception caught: \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in range(len(img_name_arr)):\n",
    "    # Set paths\n",
    "    if model_prefix == \"-CRR\":\n",
    "        img_name = img_name_arr[it]\n",
    "        save_dir = CRR_save_dir\n",
    "        save_var_dir = load_var_dir\n",
    "\n",
    "    saving_var_path = \"{:s}{:s}{:s}{:s}\".format(\n",
    "        save_var_dir,\n",
    "        img_name,\n",
    "        model_prefix,\n",
    "        \"-new_pixel_UQ_vars.npy\",\n",
    "    )\n",
    "\n",
    "    data = np.load(saving_var_path, allow_pickle=True)[()]\n",
    "\n",
    "    print(\"\\n\\n\", img_name)\n",
    "    print(\"SNR (MAP vs GT): \\t\\t\\t\", qai.utils.eval_snr(data[\"gt\"], data[\"map\"]))\n",
    "    for modif_level in range(levels + 1):\n",
    "        print(\n",
    "            \"SNR (MAP vs GT) at lvl {:d}: \\t\\t\\t{:.2f}\".format(\n",
    "                modif_level, data[\"SNR_at_lvl_map_vs_GT\"][modif_level]\n",
    "            )\n",
    "        )\n",
    "    print(\n",
    "        \"SNR (thresh vs MAP): \\t\\t\\t\",\n",
    "        qai.utils.eval_snr(data[\"map\"], data[\"thresholded_img\"]),\n",
    "    )\n",
    "    for modif_level in range(levels + 1):\n",
    "        print(\n",
    "            \"SNR (thresh vs MAP) at lvl {:d}: \\t\\t\\t{:.2f}\".format(\n",
    "                modif_level, data[\"SNR_at_level\"][modif_level]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convex_uq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "2bb75ebd6ceb1eff2ce987e124c91bc6f99e62fd1930d98a82dc138614104eef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
