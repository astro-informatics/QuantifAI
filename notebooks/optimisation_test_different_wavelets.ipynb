{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "1\n",
            "0\n",
            "NVIDIA A100-PCIE-40GB\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import math\n",
        "import time as time\n",
        "\n",
        "import torch\n",
        "M1 = False\n",
        "\n",
        "if M1:\n",
        "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "else:\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    if torch.cuda.is_available():\n",
        "        print(torch.cuda.is_available())\n",
        "        print(torch.cuda.device_count())\n",
        "        print(torch.cuda.current_device())\n",
        "        print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "import large_scale_UQ as luq\n",
        "from large_scale_UQ.utils import to_numpy, to_tensor\n",
        "from convex_reg import utils as utils_cvx_reg\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_name = 'W28' # 'M31'\n",
        "# Input noise level\n",
        "input_snr = 30."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Benchmark wavelet-based model optimisation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimisation options for the MAP estimation\n",
        "options = {\"tol\": 1e-5, \"iter\": 15000, \"update_iter\": 4999, \"record_iters\": False}\n",
        "# Save param\n",
        "repo_dir = '/disk/xray0/tl3/repos/large-scale-UQ'\n",
        "\n",
        "\n",
        "# Define my torch types (CRR requires torch.float32, wavelets require torch.float64)\n",
        "myType = torch.float64\n",
        "myComplexType = torch.complex128\n",
        "\n",
        "# Wavelet parameters\n",
        "reg_params = [5e2] # [5e2, 5e1, 1e3, 5e3, 1e4, 5e4]\n",
        "wavs_list = ['db1','db2','db3','db4','db5','db6','db7','db8']\n",
        "levels = 4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%\n",
        "# Load image and mask\n",
        "img, mat_mask = luq.helpers.load_imgs(img_name, repo_dir)\n",
        "\n",
        "# Aliases\n",
        "x = img\n",
        "ground_truth = img\n",
        "\n",
        "torch_img = torch.tensor(\n",
        "    np.copy(img), dtype=myType, device=device).reshape((1,1) + img.shape\n",
        ")\n",
        "\n",
        "phi = luq.operators.MaskedFourier_torch(\n",
        "    shape=img.shape, \n",
        "    ratio=0.5 ,\n",
        "    mask=mat_mask,\n",
        "    norm='ortho',\n",
        "    device=device\n",
        ")\n",
        "\n",
        "y = phi.dir_op(torch_img).detach().cpu().squeeze().numpy()\n",
        "\n",
        "# Define X Cai noise level\n",
        "eff_sigma = luq.helpers.compute_complex_sigma_noise(y, input_snr)\n",
        "sigma = eff_sigma * np.sqrt(2)\n",
        "\n",
        "# Generate noise\n",
        "rng = np.random.default_rng(seed=0)\n",
        "n_re = rng.normal(0, eff_sigma, y[y!=0].shape)\n",
        "n_im = rng.normal(0, eff_sigma, y[y!=0].shape)\n",
        "# Add noise\n",
        "y[y!=0] += (n_re + 1.j*n_im)\n",
        "\n",
        "# Observation\n",
        "torch_y = torch.tensor(np.copy(y), device=device, dtype=myComplexType).reshape((1,) + img.shape)\n",
        "x_init = torch.abs(phi.adj_op(torch_y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold:  0.0025999027914999657\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "# Define the likelihood\n",
        "g = luq.operators.L2Norm_torch(\n",
        "    sigma=sigma,\n",
        "    data=torch_y,\n",
        "    Phi=phi,\n",
        ")\n",
        "# Lipschitz constant computed automatically by g, stored in g.beta\n",
        "\n",
        "# Define real prox\n",
        "f = luq.operators.RealProx_torch()\n",
        "\n",
        "# %%\n",
        "\n",
        "\n",
        "# Prior parameters\n",
        "reg_param = 5e2\n",
        "\n",
        "# Define the wavelet dict\n",
        "# Define the l1 norm with dict psi\n",
        "psi = luq.operators.DictionaryWv_torch(wavs_list, levels)\n",
        "h = luq.operators.L1Norm_torch(1., psi, op_to_coeffs=True)\n",
        "h.gamma = reg_param\n",
        "\n",
        "# Compute stepsize\n",
        "alpha = 0.98 / g.beta\n",
        "\n",
        "# Effective threshold\n",
        "print('Threshold: ', h.gamma * alpha)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Base Forward Backward\n",
            "[Forward Backward] 0 out of 15000 iterations, tol = 5.16e-01\n",
            "[Forward Backward] converged in 144 iterations\n"
          ]
        }
      ],
      "source": [
        "# Run the optimisation\n",
        "x_hat, diagnostics = luq.optim.FB_torch(\n",
        "    torch.clone(x_init),\n",
        "    options=options,\n",
        "    g=g,\n",
        "    f=f,\n",
        "    h=h,\n",
        "    alpha=alpha,\n",
        "    tau=alpha,\n",
        "    viewer=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Base Forward Backward\n",
            "[Forward Backward] 0 out of 15000 iterations, tol = 5.18e-01\n",
            "[Forward Backward] converged in 207 iterations\n",
            "Running Base Forward Backward\n",
            "[Forward Backward] 0 out of 15000 iterations, tol = 5.18e-01\n",
            "[Forward Backward] converged in 207 iterations\n",
            "Running Base Forward Backward\n",
            "[Forward Backward] 0 out of 15000 iterations, tol = 5.18e-01\n",
            "[Forward Backward] converged in 207 iterations\n",
            "Running Base Forward Backward\n",
            "[Forward Backward] 0 out of 15000 iterations, tol = 5.18e-01\n",
            "[Forward Backward] converged in 207 iterations\n",
            "Running Base Forward Backward\n",
            "[Forward Backward] 0 out of 15000 iterations, tol = 5.18e-01\n",
            "[Forward Backward] converged in 207 iterations\n",
            "Running Base Forward Backward\n",
            "[Forward Backward] 0 out of 15000 iterations, tol = 5.18e-01\n",
            "[Forward Backward] converged in 207 iterations\n",
            "Running Base Forward Backward\n",
            "[Forward Backward] 0 out of 15000 iterations, tol = 5.18e-01\n",
            "[Forward Backward] converged in 207 iterations\n",
            "Running Base Forward Backward\n",
            "[Forward Backward] 0 out of 15000 iterations, tol = 5.18e-01\n",
            "[Forward Backward] converged in 207 iterations\n",
            "1.3 s ± 721 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "# Run the optimisation\n",
        "x_hat, diagnostics = luq.optim.FB_torch(\n",
        "    torch.clone(x_init),\n",
        "    options=options,\n",
        "    g=g,\n",
        "    f=f,\n",
        "    h=h,\n",
        "    alpha=alpha,\n",
        "    tau=alpha,\n",
        "    viewer=None\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%\n",
        "np_x_init = to_numpy(x_init)\n",
        "np_x = np.copy(x)\n",
        "np_x_hat = to_numpy(x_hat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dirty image SNR:  3.39\n",
            "Dirty image SNR:  23.68\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print('Dirty image SNR: ', luq.utils.eval_snr(np_x, np_x_init))\n",
        "print('Dirty image SNR: ', luq.utils.eval_snr(np_x, np_x_hat))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "convex_uq",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "2bb75ebd6ceb1eff2ce987e124c91bc6f99e62fd1930d98a82dc138614104eef"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
