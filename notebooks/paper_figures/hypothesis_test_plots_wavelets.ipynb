{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import time as time\n",
        "\n",
        "import torch\n",
        "M1 = False\n",
        "\n",
        "if M1:\n",
        "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "else:\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    if torch.cuda.is_available():\n",
        "        print(torch.cuda.is_available())\n",
        "        print(torch.cuda.device_count())\n",
        "        print(torch.cuda.current_device())\n",
        "        print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.ticker as tick\n",
        "\n",
        "import scipy as sp\n",
        "import large_scale_UQ as luq\n",
        "from large_scale_UQ.utils import to_numpy, to_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save param\n",
        "repo_dir = '/disk/xray0/tl3/repos/large-scale-UQ'\n",
        "\n",
        "# save_dir = '/disk/xray0/tl3/outputs/large-scale-UQ/def_UQ_results/wavelets/hypothesis_test_paper_figs/'\n",
        "# load_var_dir = '/disk/xray0/tl3/outputs/large-scale-UQ/def_UQ_results/wavelets/vars/'\n",
        "\n",
        "new_wav_reg_strength = True\n",
        "save_results = True\n",
        "\n",
        "if new_wav_reg_strength:\n",
        "    # New wavelet reg strength\n",
        "    save_dir = '/disk/xray0/tl3/outputs/large-scale-UQ/def_UQ_results/v2/wavelets_new_reg_strength/hypothesis_test_paper_figs/'\n",
        "    load_var_dir = '/disk/xray99/tl3/proj-convex-UQ/outputs/new_UQ_results/wavelets_new_reg_strength/vars/'\n",
        "else:\n",
        "    # Original wavelet reg strength\n",
        "    save_dir = '/disk/xray0/tl3/outputs/large-scale-UQ/def_UQ_results/v2/wavelets/hypothesis_test_paper_figs/'\n",
        "    load_var_dir = '/disk/xray99/tl3/proj-convex-UQ/outputs/new_UQ_results/wavelets/vars/'\n",
        "\n",
        "\n",
        "# Confidence value\n",
        "alpha_prob = 0.01\n",
        "# Blurring Gaussian St Dev\n",
        "G_sigma = 3.5 # 1.02\n",
        "\n",
        "# Inpatinting params\n",
        "inptaint_options = {\n",
        "    \"tol\": 5e-6,\n",
        "    \"iter\": 15000,\n",
        "    \"update_iter\": 4999,\n",
        "    \"record_iters\": False\n",
        "}\n",
        "\n",
        "map_potential_list = []\n",
        "likelihood_map_potential_list = []\n",
        "prior_map_potential_list = []\n",
        "surrogate_potential_list = []\n",
        "likelihood_surrogate_potential_list = []\n",
        "prior_surrogate_potential_list = []\n",
        "gamma_alpha_list = []\n",
        "Hnot_reject_list = []\n",
        "potential_blurring_list = []\n",
        "Hnot_reject_blurring_list = []\n",
        "\n",
        "\n",
        "cmap = 'cubehelix'\n",
        "model_prefix = '-WAV'\n",
        "input_snr = 30.\n",
        "cbar_font_size = 18\n",
        "\n",
        "\n",
        "\n",
        "if new_wav_reg_strength:\n",
        "    # Wavelet parameters\n",
        "    reg_param = 1e2 #\n",
        "    wavs_list = ['db8']\n",
        "    levels = 4\n",
        "    # New wavelet reg strength\n",
        "    map_vars_path_arr = [\n",
        "        load_var_dir+'CYN_wavelets_UQ_MAP_reg_param_1.0e+02_MAP_vars.npy',\n",
        "        load_var_dir+'M31_wavelets_UQ_MAP_reg_param_1.0e+02_MAP_vars.npy',\n",
        "        load_var_dir+'3c288_wavelets_UQ_MAP_reg_param_1.0e+02_MAP_vars.npy',\n",
        "        load_var_dir+'3c288_wavelets_UQ_MAP_reg_param_1.0e+02_MAP_vars.npy',\n",
        "        load_var_dir+'W28_wavelets_UQ_MAP_reg_param_1.0e+02_MAP_vars.npy',\n",
        "    ]\n",
        "    samp_vars_path_arr = [\n",
        "        load_var_dir+'CYN_SKROCK_wavelets_reg_param_1.0e+02_nsamples_5.0e+04_thinning_1.0e+01_vars.npy',\n",
        "        load_var_dir+'M31_SKROCK_wavelets_reg_param_1.0e+02_nsamples_5.0e+04_thinning_1.0e+01_vars.npy',\n",
        "        load_var_dir+'3c288_SKROCK_wavelets_reg_param_1.0e+02_nsamples_5.0e+04_thinning_1.0e+01_vars.npy',\n",
        "        load_var_dir+'3c288_SKROCK_wavelets_reg_param_1.0e+02_nsamples_5.0e+04_thinning_1.0e+01_vars.npy',\n",
        "        load_var_dir+'W28_SKROCK_wavelets_reg_param_1.0e+02_nsamples_5.0e+04_thinning_1.0e+01_vars.npy',    \n",
        "    ]\n",
        "else:\n",
        "    # Wavelet parameters\n",
        "    reg_param = 5e2 #\n",
        "    wavs_list = ['db8']\n",
        "    levels = 4\n",
        "    # Original wavelet reg strength\n",
        "    map_vars_path_arr = [\n",
        "        load_var_dir+'CYN_wavelets_UQ_MAP_reg_param_5.0e+02_MAP_vars.npy',\n",
        "        load_var_dir+'M31_wavelets_UQ_MAP_reg_param_5.0e+02_MAP_vars.npy',\n",
        "        load_var_dir+'3c288_wavelets_UQ_MAP_reg_param_5.0e+02_MAP_vars.npy',\n",
        "        load_var_dir+'3c288_wavelets_UQ_MAP_reg_param_5.0e+02_MAP_vars.npy',\n",
        "        load_var_dir+'W28_wavelets_UQ_MAP_reg_param_5.0e+02_MAP_vars.npy',\n",
        "    ]\n",
        "    samp_vars_path_arr = [\n",
        "        load_var_dir+'CYN_SKROCK_wavelets_reg_param_5.0e+02_nsamples_5.0e+04_thinning_1.0e+01_vars.npy',\n",
        "        load_var_dir+'M31_SKROCK_wavelets_reg_param_5.0e+02_nsamples_5.0e+04_thinning_1.0e+01_vars.npy',\n",
        "        load_var_dir+'3c288_SKROCK_wavelets_reg_param_5.0e+02_nsamples_5.0e+04_thinning_1.0e+01_vars.npy',\n",
        "        load_var_dir+'3c288_SKROCK_wavelets_reg_param_5.0e+02_nsamples_5.0e+04_thinning_1.0e+01_vars.npy',\n",
        "        load_var_dir+'W28_SKROCK_wavelets_reg_param_5.0e+02_nsamples_5.0e+04_thinning_1.0e+01_vars.npy',    \n",
        "    ]\n",
        "\n",
        "img_name_list = ['CYN', 'M31', '3c288', '3c288','W28']\n",
        "pysiscal_list = [True, True, True, False, True]\n",
        "vmin_log_arr = [-3., -2., -2., -2., -2.]\n",
        "text_str_arr = [r'$1$',r'$1$',r'$1$',r'$2$',r'$1$']\n",
        "saving_text_str_arr = ['1', '1', '1', '2', '1']\n",
        "text_pos_arr = [\n",
        "    [0, 0.12],\n",
        "    [0, 0.06],\n",
        "    [0, 0.06],\n",
        "    [-0.05, -0.01],\n",
        "    [0, 0.06],\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Define the wavelet dict\n",
        "# Define the l1 norm with dict psi\n",
        "psi = luq.operators.DictionaryWv_torch(wavs_list, levels)\n",
        "h = luq.operators.L1Norm_torch(1., psi, op_to_coeffs=True)\n",
        "# Prior parameter\n",
        "h.gamma = reg_param\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "for it_img in range(len(img_name_list)):\n",
        "\n",
        "    img_name = img_name_list[it_img]\n",
        "    map_vars_path = map_vars_path_arr[it_img]\n",
        "    samp_vars_path = samp_vars_path_arr[it_img]\n",
        "    vmin_log = vmin_log_arr[it_img]\n",
        "\n",
        "    text_pos = text_pos_arr[it_img]\n",
        "    textstr = text_str_arr[it_img]\n",
        "    saving_text_str = saving_text_str_arr[it_img]\n",
        "\n",
        "    # Load variables\n",
        "    map_vars = np.load(map_vars_path, allow_pickle=True)[()]\n",
        "    samp_vars = np.load(samp_vars_path, allow_pickle=True)[()]\n",
        "\n",
        "    # Load image and mask\n",
        "    img, mat_mask = luq.helpers.load_imgs(img_name, repo_dir)\n",
        "\n",
        "    # Define my torch types\n",
        "    myType = torch.float64\n",
        "    myComplexType = torch.complex128\n",
        "\n",
        "\n",
        "    # Aliases\n",
        "    x = img\n",
        "    ground_truth = img\n",
        "    # Prepare inputs and functions\n",
        "    torch_img = torch.tensor(\n",
        "        np.copy(img), dtype=myType, device=device).reshape((1,1) + img.shape\n",
        "    )\n",
        "    phi = luq.operators.MaskedFourier_torch(\n",
        "        shape=img.shape, \n",
        "        ratio=0.5 ,\n",
        "        mask=mat_mask,\n",
        "        norm='ortho',\n",
        "        device=device\n",
        "    )\n",
        "    y = phi.dir_op(torch_img).detach().cpu().squeeze().numpy()\n",
        "\n",
        "    # Define X Cai noise level\n",
        "    eff_sigma = luq.helpers.compute_complex_sigma_noise(y, input_snr)\n",
        "    sigma = eff_sigma * np.sqrt(2)\n",
        "\n",
        "    # Generate noise\n",
        "    rng = np.random.default_rng(seed=0)\n",
        "    n_re = rng.normal(0, eff_sigma, y[y!=0].shape)\n",
        "    n_im = rng.normal(0, eff_sigma, y[y!=0].shape)\n",
        "    # Add noise\n",
        "    y[y!=0] += (n_re + 1.j*n_im)\n",
        "\n",
        "    # Observation\n",
        "    torch_y = torch.tensor(np.copy(y), device=device, dtype=myComplexType).reshape((1,) + img.shape)\n",
        "    x_init = torch.abs(phi.adj_op(torch_y))\n",
        "\n",
        "    # %%\n",
        "    # Define the likelihood\n",
        "    g = luq.operators.L2Norm_torch(\n",
        "        sigma=sigma,\n",
        "        data=torch_y,\n",
        "        Phi=phi,\n",
        "    )\n",
        "    # Lipschitz constant computed automatically by g, stored in g.beta\n",
        "\n",
        "    # Define real prox\n",
        "    f = luq.operators.RealProx_torch()\n",
        "\n",
        "\n",
        "    # Extract variables\n",
        "    x_gt = samp_vars['X_ground_truth']\n",
        "    x_dirty = samp_vars['X_dirty']\n",
        "    x_map = samp_vars['X_MAP']\n",
        "    x_mmse = samp_vars['X_MMSE']\n",
        "\n",
        "    # Inpainting\n",
        "    # Load mask details\n",
        "    pysiscal = pysiscal_list[it_img]\n",
        "    mask_x, mask_y = luq.helpers.get_hypothesis_test_mask(img_name, pysiscal)\n",
        "    # Prepare mask\n",
        "    np_mask_inpainting = np.zeros((img.shape[0], img.shape[1]))\n",
        "    np_mask_inpainting[mask_x[0]:mask_x[1], mask_y[0]:mask_y[1]] = 1\n",
        "    # Prepare inpaint image\n",
        "    inpaint_img = np.copy(x_map)\n",
        "    inpaint_img[np_mask_inpainting.astype(bool)] = 0\n",
        "\n",
        "\n",
        "    mask_inpainting = to_tensor(np_mask_inpainting)\n",
        "    x_init_imp = to_tensor(inpaint_img)\n",
        "\n",
        "    # Define rectangle coordinates\n",
        "    rect_anchor_xy = (mask_y[0], mask_x[0])\n",
        "    rect_width = mask_y[1] - mask_y[0]\n",
        "    rect_height = mask_x[1] - mask_x[0]\n",
        "    # Define text attributes\n",
        "    font = {\n",
        "        'color':  'red',\n",
        "        'weight': 'normal',\n",
        "        'size': 18,\n",
        "    }\n",
        "\n",
        "    fig = plt.figure(figsize=(5,5), dpi=200)\n",
        "    axs = plt.gca()\n",
        "    plt_im = axs.imshow(np.log10(np.abs(x_map)), cmap=cmap, vmin=vmin_log, vmax=0)\n",
        "    divider = make_axes_locatable(axs)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    cbar = fig.colorbar(plt_im, cax=cax)\n",
        "    cbar.ax.yaxis.set_major_formatter(tick.FormatStrFormatter('%.1f'))\n",
        "    cbar.ax.tick_params(labelsize=cbar_font_size)\n",
        "    axs.set_yticks([]);axs.set_xticks([])\n",
        "    plt.tight_layout()\n",
        "    if save_results:\n",
        "        plt.savefig(\n",
        "            '{:s}{:s}{:s}{:s}{:s}{:s}'.format(\n",
        "                save_dir, img_name, model_prefix, '_region_', saving_text_str, '-MAP_image.pdf'\n",
        "            ),\n",
        "            bbox_inches='tight',\n",
        "            dpi=200\n",
        "        )\n",
        "    plt.show()\n",
        "\n",
        "    fig = plt.figure(figsize=(5,5), dpi=200)\n",
        "    axs = plt.gca()\n",
        "    plt_im = axs.imshow(np.log10(np.abs(x_map)), cmap=cmap, vmin=vmin_log, vmax=0)\n",
        "    divider = make_axes_locatable(axs)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    cbar = fig.colorbar(plt_im, cax=cax)\n",
        "    cbar.ax.yaxis.set_major_formatter(tick.FormatStrFormatter('%.1f'))\n",
        "    cbar.ax.tick_params(labelsize=cbar_font_size)\n",
        "    axs.set_yticks([]);axs.set_xticks([])\n",
        "    # Create a Rectangle patch\n",
        "    rect = patches.Rectangle(\n",
        "        rect_anchor_xy, rect_width, rect_height,\n",
        "        linewidth=1, edgecolor='r', facecolor='none'\n",
        "    )\n",
        "    # Add the patch to the Axes\n",
        "    axs.add_patch(rect)\n",
        "    axs.text(\n",
        "        rect_anchor_xy[0]/x_map.shape[1] + text_pos[0],\n",
        "        1 - rect_anchor_xy[1]/x_map.shape[0] + text_pos[1],\n",
        "        textstr, transform=axs.transAxes, \n",
        "        fontdict=font, verticalalignment='top'\n",
        "    )\n",
        "    plt.tight_layout()\n",
        "    if save_results:\n",
        "        plt.savefig(\n",
        "            '{:s}{:s}{:s}{:s}{:s}{:s}'.format(\n",
        "                save_dir, img_name, model_prefix, '_region_', saving_text_str, '-MAP_image_inpaintedRegion.pdf'\n",
        "            ),\n",
        "            bbox_inches='tight',\n",
        "            dpi=200\n",
        "        )\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # To tensor\n",
        "    x_map_torch = to_tensor(x_map)\n",
        "\n",
        "    # Compute stepsize\n",
        "    alpha = 0.98 / g.beta\n",
        "\n",
        "    # initialization\n",
        "    x_hat = torch.clone(x_init_imp)\n",
        "    z = torch.clone(x_init_imp)\n",
        "    t = 1\n",
        "\n",
        "    # Set subtraction operation\n",
        "    _op_sub = lambda _x1, _x2 : _x1 - _x2\n",
        "    if h.num_wavs > 0:\n",
        "        op_sub = partial(h._op_to_two_coeffs, op=_op_sub)\n",
        "    # Set parameter\n",
        "    tau = alpha\n",
        "\n",
        "    for it_2 in range(inptaint_options['iter']):\n",
        "        x_hat_old = torch.clone(x_hat)\n",
        "        \n",
        "        # backward step\n",
        "        u = h.dir_op(x_hat)\n",
        "        u2 = h.dir_op(torch.clone(x_hat))\n",
        "        x_hat = x_hat + h.adj_op(op_sub(h.prox(u, tau), u2))\n",
        "        # Apply constraint\n",
        "        x_hat = f.prox(x_hat)\n",
        "\n",
        "        x_hat = torch.clone(x_hat) * mask_inpainting + torch.clone(x_map_torch) * (1. - mask_inpainting)\n",
        "        \n",
        "        t_old = t \n",
        "        t = 0.5 * (1 + math.sqrt(1 + 4*t**2))\n",
        "        z = x_hat + (t_old - 1)/t * (x_hat - x_hat_old)\n",
        "\n",
        "        # relative change of norm for terminating\n",
        "        res = (torch.norm(x_hat_old - x_hat)/torch.norm(x_hat_old)).item()\n",
        "\n",
        "        if res < inptaint_options['tol']:\n",
        "            print(\"[GD] converged in %d iterations\"%(it_2))\n",
        "            break\n",
        "\n",
        "        if it_2 % inptaint_options['update_iter'] == 0:\n",
        "            print(\n",
        "                \"[GD] %d out of %d iterations, tol = %f\" %(            \n",
        "                    it_2,\n",
        "                    inptaint_options['iter'],\n",
        "                    res,\n",
        "                )\n",
        "            )\n",
        "\n",
        "    x_map_torch = to_tensor(x_map)\n",
        "\n",
        "    # Generate surrogate impainted img\n",
        "    surrogate_img = torch.clone(x_hat) * mask_inpainting + torch.clone(x_map_torch) * (1. - mask_inpainting)\n",
        "\n",
        "    imp_surrogate = to_numpy(torch.clone(surrogate_img))\n",
        "\n",
        "    # Define rectangle coordinates\n",
        "    rect_anchor_xy = (mask_y[0], mask_x[0])\n",
        "    rect_width = mask_y[1] - mask_y[0]\n",
        "    rect_height = mask_x[1] - mask_x[0]\n",
        "    # Define text attributes\n",
        "    font = {\n",
        "        'color':  'red',\n",
        "        'weight': 'normal',\n",
        "        'size': 18,\n",
        "    }\n",
        "\n",
        "    fig = plt.figure(figsize=(5,5), dpi=200)\n",
        "    axs = plt.gca()\n",
        "    plt_im = axs.imshow(np.log10(np.abs(imp_surrogate)), cmap=cmap, vmin=vmin_log, vmax=0)\n",
        "    divider = make_axes_locatable(axs)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    cbar = fig.colorbar(plt_im, cax=cax)\n",
        "    cbar.ax.yaxis.set_major_formatter(tick.FormatStrFormatter('%.1f'))\n",
        "    cbar.ax.tick_params(labelsize=cbar_font_size)\n",
        "    axs.set_yticks([]);axs.set_xticks([])\n",
        "\n",
        "    # Create a Rectangle patch\n",
        "    rect = patches.Rectangle(\n",
        "        rect_anchor_xy, rect_width, rect_height,\n",
        "        linewidth=1, edgecolor='r', facecolor='none'\n",
        "    )\n",
        "    # Add the patch to the Axes\n",
        "    axs.add_patch(rect)\n",
        "    axs.text(\n",
        "        rect_anchor_xy[0]/x_map.shape[1] + text_pos[0],\n",
        "        1 - rect_anchor_xy[1]/x_map.shape[0] + text_pos[1],\n",
        "        textstr, transform=axs.transAxes, \n",
        "        fontdict=font, verticalalignment='top'\n",
        "    )\n",
        "    plt.tight_layout()\n",
        "    if save_results:\n",
        "        plt.savefig(\n",
        "            '{:s}{:s}{:s}{:s}{:s}{:s}'.format(\n",
        "                save_dir, img_name, model_prefix, '_region_', saving_text_str, '-inpaintedSurrogate_maskRegion.pdf'\n",
        "            ),\n",
        "            bbox_inches='tight',\n",
        "            dpi=200\n",
        "        )\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    #function handles for the hypothesis test\n",
        "\n",
        "    # Evaluation of the potentials\n",
        "    # Prior potential\n",
        "    prior_fun = lambda _x : h._fun_coeffs(h.dir_op(_x))\n",
        "    # Posterior potential\n",
        "    fun = lambda _x : g.fun(_x) +  prior_fun(_x)\n",
        "    # Evaluation of the potential in numpy\n",
        "    fun_np = lambda _x : fun(to_tensor(_x, dtype=myType)).item()\n",
        "\n",
        "    # Compute HPD region bound\n",
        "    N = x_map.size\n",
        "    tau_alpha = np.sqrt(16*np.log(3/alpha_prob))\n",
        "    gamma_alpha = fun(x_map_torch).item() + tau_alpha*np.sqrt(N) + N\n",
        "\n",
        "    print('gamma_alpha: ', gamma_alpha)\n",
        "    print('fun(x_map).item(): ', fun(x_map_torch).item())\n",
        "    print('tau_alpha*np.sqrt(N) + N: ', tau_alpha*np.sqrt(N) + N)\n",
        "\n",
        "    # Compute potential\n",
        "    map_potential = fun(x_map_torch).item()\n",
        "    potential = fun(surrogate_img).item()\n",
        "\n",
        "    # Decompose potentials\n",
        "    map_likelihood_potential = g.fun(x_map_torch).item()\n",
        "    map_prior_potential = prior_fun(x_map_torch).item()\n",
        "    surrogate_likelihood_potential = g.fun(surrogate_img).item()\n",
        "    surrogate_prior_potential = prior_fun(surrogate_img).item()\n",
        "\n",
        "    if potential > gamma_alpha:\n",
        "        print(img_name, ': Inpainted area nonremovable! (Reject H0)')\n",
        "        Hnot_reject = True\n",
        "    else:\n",
        "        print(img_name, ': Inpainted area removable! (Cannot reject H0)')\n",
        "        Hnot_reject = False\n",
        "    # Print values\n",
        "    print(img_name, '_gamma_alpha: ', gamma_alpha)\n",
        "    print(img_name, '_potential: ', potential)\n",
        "    print(img_name, '-MAP_potential: ', map_potential)\n",
        "    # Save values\n",
        "    map_potential_list.append(map_potential)\n",
        "    surrogate_potential_list.append(potential)\n",
        "    gamma_alpha_list.append(gamma_alpha)\n",
        "    Hnot_reject_list.append(Hnot_reject)\n",
        "    # Save decomposed potentials\n",
        "    likelihood_map_potential_list.append(map_likelihood_potential)\n",
        "    prior_map_potential_list.append(map_prior_potential)\n",
        "    likelihood_surrogate_potential_list.append(surrogate_likelihood_potential)\n",
        "    prior_surrogate_potential_list.append(surrogate_prior_potential)\n",
        "\n",
        "\n",
        "    # Hypothesis test of blurred image\n",
        "    gauss_blurred_im_np = sp.ndimage.gaussian_filter(\n",
        "        input=np.copy(x_map),\n",
        "        sigma=G_sigma,\n",
        "        radius=np.int64(np.floor(2*G_sigma)),\n",
        "    )\n",
        "    gauss_blurred_im = to_tensor(gauss_blurred_im_np)\n",
        "\n",
        "\n",
        "    # Compute potential\n",
        "    potential_blurring = fun(gauss_blurred_im).item()\n",
        "\n",
        "    if potential_blurring > gamma_alpha:\n",
        "        print(img_name, ': Blurred structure is physical! (Reject H0)')\n",
        "        Hnot_reject_blurring = True\n",
        "    else:\n",
        "        print(img_name, ': Cannot conclude if blurred structure is physical! (Cannot reject H0)')\n",
        "        Hnot_reject_blurring = False\n",
        "    # Print values\n",
        "    print(img_name, '_gamma_alpha: ', gamma_alpha)\n",
        "    print(img_name, '_potential_blurring: ', potential_blurring)\n",
        "    print(img_name, '-MAP_potential: ', map_potential)\n",
        "    # Save values\n",
        "    potential_blurring_list.append(potential_blurring)\n",
        "    Hnot_reject_blurring_list.append(Hnot_reject_blurring)\n",
        "\n",
        "    # Plot image\n",
        "    fig = plt.figure(figsize=(5,5), dpi=200)\n",
        "    axs = plt.gca()\n",
        "    plt_im = axs.imshow(np.log10(np.abs(to_numpy(gauss_blurred_im))), cmap=cmap, vmin=vmin_log, vmax=0)\n",
        "    divider = make_axes_locatable(axs)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    cbar = fig.colorbar(plt_im, cax=cax)\n",
        "    cbar.ax.yaxis.set_major_formatter(tick.FormatStrFormatter('%.1f'))\n",
        "    cbar.ax.tick_params(labelsize=cbar_font_size)\n",
        "    axs.set_yticks([]);axs.set_xticks([])\n",
        "    plt.tight_layout()\n",
        "    if save_results:\n",
        "        plt.savefig(\n",
        "            '{:s}{:s}{:s}{:s}{:.2f}{:s}'.format(\n",
        "                save_dir, img_name, model_prefix, '-blurred_surrogate_image_Gsigma_', G_sigma, '.pdf'\n",
        "            ),\n",
        "            bbox_inches='tight',\n",
        "            dpi=200\n",
        "        )\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "params_dict = {\n",
        "    'model_prefix': model_prefix,\n",
        "    'inptaint_options': inptaint_options,\n",
        "    'reg_param': reg_param,\n",
        "    'wavs_list': wavs_list,\n",
        "    'levels': levels,\n",
        "    'G_sigma': G_sigma,\n",
        "}\n",
        "\n",
        "save_dict = {\n",
        "    'params_dict': params_dict,\n",
        "    'alpha_prob': alpha_prob,\n",
        "    'map_potential_list': map_potential_list,\n",
        "    'surrogate_potential_list': surrogate_potential_list,\n",
        "    'likelihood_map_potential_list': likelihood_map_potential_list,\n",
        "    'prior_map_potential_list': prior_map_potential_list,\n",
        "    'likelihood_surrogate_potential_list': likelihood_surrogate_potential_list,\n",
        "    'prior_surrogate_potential_list': prior_surrogate_potential_list,\n",
        "    'gamma_alpha_list': gamma_alpha_list,\n",
        "    'Hnot_reject_list': Hnot_reject_list,\n",
        "    'potential_blurring_list': potential_blurring_list,\n",
        "    'Hnot_reject_blurring_list': Hnot_reject_blurring_list,\n",
        "    'map_vars_path_arr': map_vars_path_arr,\n",
        "    'samp_vars_path_arr': samp_vars_path_arr,\n",
        "    'img_name_list': img_name_list,\n",
        "    'pysiscal_list': pysiscal_list,\n",
        "    'vmin_log_arr': vmin_log_arr,\n",
        "    'text_str_arr': text_str_arr,\n",
        "    'text_pos_arr': text_pos_arr,\n",
        "}\n",
        "\n",
        "\n",
        "# Save variables\n",
        "if save_results:\n",
        "    try:\n",
        "        save_path = '{:s}{:s}{:s}{:s}'.format(\n",
        "            save_dir, 'hypothesisTest', model_prefix, '_vars.npy'\n",
        "        )\n",
        "        if os.path.isfile(save_path):\n",
        "            os.remove(save_path)\n",
        "        np.save(save_path, save_dict, allow_pickle=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        print('Could not save vairables. Exception caught: ', e)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "img:  CYN\n",
            "Hypothesis test: Blurring\n",
            "Threshold: \t\t 177731.89701819158\n",
            "MAP potential: \t\t 43201.328119891274\n",
            "Blurring potential: \t 988929.251827355\n",
            "H0 reject: \t\t True\n",
            " \n",
            "Hypothesis test: Inpainting\n",
            "Threshold: \t\t 177731.89701819158\n",
            "MAP potential: \t\t 43201.328119891274\n",
            "\tMAP likelihood pot.: \t\t 672.769526141271\n",
            "\tMAP prior pot.: \t\t\t 42528.55859375\n",
            "\tMAP prior/likelihood ratio: \t 63.214157213208374\n",
            "Surrogate potential: \t 50583.45357724391\n",
            "\tSurr. likelihood pot.: \t\t 8282.047327243916\n",
            "\tSurr. prior pot.: \t\t\t 42301.40625\n",
            "\tSurr. prior/likelihood ratio: \t 5.10760257440801\n",
            "H0 reject: \t\t False\n",
            "\n",
            "\n",
            "img:  M31\n",
            "Hypothesis test: Blurring\n",
            "Threshold: \t\t 103924.40757539387\n",
            "MAP potential: \t\t 35942.83005420483\n",
            "Blurring potential: \t 196310.4574163742\n",
            "H0 reject: \t\t True\n",
            " \n",
            "Hypothesis test: Inpainting\n",
            "Threshold: \t\t 103924.40757539387\n",
            "MAP potential: \t\t 35942.83005420483\n",
            "\tMAP likelihood pot.: \t\t 3410.433569829829\n",
            "\tMAP prior pot.: \t\t\t 32532.396484375\n",
            "\tMAP prior/likelihood ratio: \t 9.539079362861852\n",
            "Surrogate potential: \t 133447.81493460282\n",
            "\tSurr. likelihood pot.: \t\t 104890.62352835282\n",
            "\tSurr. prior pot.: \t\t\t 28557.19140625\n",
            "\tSurr. prior/likelihood ratio: \t 0.2722568561958329\n",
            "H0 reject: \t\t True\n",
            "\n",
            "\n",
            "img:  3c288\n",
            "Hypothesis test: Blurring\n",
            "Threshold: \t\t 133279.1724133803\n",
            "MAP potential: \t\t 65297.59489219124\n",
            "Blurring potential: \t 133043.30314137612\n",
            "H0 reject: \t\t False\n",
            " \n",
            "Hypothesis test: Inpainting\n",
            "Threshold: \t\t 133279.1724133803\n",
            "MAP potential: \t\t 65297.59489219124\n",
            "\tMAP likelihood pot.: \t\t 3747.383954691241\n",
            "\tMAP prior pot.: \t\t\t 61550.2109375\n",
            "\tMAP prior/likelihood ratio: \t 16.42484775557815\n",
            "Surrogate potential: \t 242286.79418463615\n",
            "\tSurr. likelihood pot.: \t\t 184308.06762213615\n",
            "\tSurr. prior pot.: \t\t\t 57978.7265625\n",
            "\tSurr. prior/likelihood ratio: \t 0.31457508784350424\n",
            "H0 reject: \t\t True\n",
            "\n",
            "\n",
            "img:  3c288\n",
            "Hypothesis test: Blurring\n",
            "Threshold: \t\t 133279.1724133803\n",
            "MAP potential: \t\t 65297.59489219124\n",
            "Blurring potential: \t 133043.30314137612\n",
            "H0 reject: \t\t False\n",
            " \n",
            "Hypothesis test: Inpainting\n",
            "Threshold: \t\t 133279.1724133803\n",
            "MAP potential: \t\t 65297.59489219124\n",
            "\tMAP likelihood pot.: \t\t 3747.383954691241\n",
            "\tMAP prior pot.: \t\t\t 61550.2109375\n",
            "\tMAP prior/likelihood ratio: \t 16.42484775557815\n",
            "Surrogate potential: \t 65361.781975821395\n",
            "\tSurr. likelihood pot.: \t\t 3809.4499445713977\n",
            "\tSurr. prior pot.: \t\t\t 61552.33203125\n",
            "\tSurr. prior/likelihood ratio: \t 16.157800450682984\n",
            "H0 reject: \t\t False\n",
            "\n",
            "\n",
            "img:  W28\n",
            "Hypothesis test: Blurring\n",
            "Threshold: \t\t 96375.94321541936\n",
            "MAP potential: \t\t 28394.365694230335\n",
            "Blurring potential: \t 844414.8256245325\n",
            "H0 reject: \t\t True\n",
            " \n",
            "Hypothesis test: Inpainting\n",
            "Threshold: \t\t 96375.94321541936\n",
            "MAP potential: \t\t 28394.365694230335\n",
            "\tMAP likelihood pot.: \t\t 1073.691866105335\n",
            "\tMAP prior pot.: \t\t\t 27320.673828125\n",
            "\tMAP prior/likelihood ratio: \t 25.445544192512948\n",
            "Surrogate potential: \t 520425.1981100824\n",
            "\tSurr. likelihood pot.: \t\t 496277.2059225824\n",
            "\tSurr. prior pot.: \t\t\t 24147.9921875\n",
            "\tSurr. prior/likelihood ratio: \t 0.04865827384235537\n",
            "H0 reject: \t\t True\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "hyp_test_path = save_dir + 'hypothesisTest-WAV_vars.npy'\n",
        "# hyp_test_path = save_path\n",
        "hyp_test_res = np.load(hyp_test_path, allow_pickle=True)[()]\n",
        "\n",
        "# print(hyp_test_res.keys())\n",
        "\n",
        "for it in range(len(hyp_test_res['img_name_list'])):\n",
        "\n",
        "    print('img: ', hyp_test_res['img_name_list'][it])\n",
        "    print('Hypothesis test: Blurring')\n",
        "    print('Threshold: \\t\\t', hyp_test_res['gamma_alpha_list'][it])\n",
        "    print('MAP potential: \\t\\t', hyp_test_res['map_potential_list'][it])\n",
        "    print('Blurring potential: \\t', hyp_test_res['potential_blurring_list'][it])\n",
        "    print('H0 reject: \\t\\t', hyp_test_res['Hnot_reject_blurring_list'][it])\n",
        "    print(' ')\n",
        "    print('Hypothesis test: Inpainting')\n",
        "    print('Threshold: \\t\\t', hyp_test_res['gamma_alpha_list'][it])\n",
        "    print('MAP potential: \\t\\t', hyp_test_res['map_potential_list'][it])\n",
        "    print('\\tMAP likelihood pot.: \\t\\t', likelihood_map_potential_list[it])\n",
        "    print('\\tMAP prior pot.: \\t\\t\\t', prior_map_potential_list[it])\n",
        "    print('\\tMAP prior/likelihood ratio: \\t', prior_map_potential_list[it]/likelihood_map_potential_list[it])\n",
        "    print('Surrogate potential: \\t', hyp_test_res['surrogate_potential_list'][it])\n",
        "    print('\\tSurr. likelihood pot.: \\t\\t', likelihood_surrogate_potential_list[it])\n",
        "    print('\\tSurr. prior pot.: \\t\\t\\t', prior_surrogate_potential_list[it])\n",
        "    print('\\tSurr. prior/likelihood ratio: \\t', prior_surrogate_potential_list[it]/likelihood_surrogate_potential_list[it])\n",
        "    print('H0 reject: \\t\\t', hyp_test_res['Hnot_reject_list'][it])\n",
        "    print('\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "convex_uq",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "2bb75ebd6ceb1eff2ce987e124c91bc6f99e62fd1930d98a82dc138614104eef"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
