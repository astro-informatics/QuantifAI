{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "1\n",
            "0\n",
            "NVIDIA A100-PCIE-40GB\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import time as time\n",
        "\n",
        "import torch\n",
        "M1 = False\n",
        "\n",
        "if M1:\n",
        "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "else:\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    if torch.cuda.is_available():\n",
        "        print(torch.cuda.is_available())\n",
        "        print(torch.cuda.device_count())\n",
        "        print(torch.cuda.current_device())\n",
        "        print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
        "\n",
        "\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from torchmetrics.functional import structural_similarity_index_measure \n",
        "from torchmetrics.functional import peak_signal_noise_ratio \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "import scipy.io as sio\n",
        "from astropy.io import fits\n",
        "import skimage as ski\n",
        "\n",
        "import large_scale_UQ as luq\n",
        "from large_scale_UQ.utils import to_numpy, to_tensor\n",
        "from convex_reg import utils as utils_cvx_reg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimisation options for the MAP estimation\n",
        "options = {\"tol\": 1e-5, \"iter\": 15000, \"update_iter\": 4999, \"record_iters\": False}\n",
        "# Save param\n",
        "repo_dir = '/disk/xray0/tl3/repos/large-scale-UQ'\n",
        "base_savedir = '/disk/xray99/tl3/proj-convex-UQ/outputs/new_UQ_results/wavelets'\n",
        "save_dir = base_savedir + '/vars/'\n",
        "savefig_dir = base_savedir + '/figs/'\n",
        "\n",
        "# Define my torch types (CRR requires torch.float32, wavelets require torch.float64)\n",
        "myType = torch.float64\n",
        "myComplexType = torch.complex128\n",
        "\n",
        "# Wavelet parameters\n",
        "reg_params = [5e2] # [5e2, 5e1, 1e3, 5e3, 1e4, 5e4]\n",
        "wavs_list = ['db8']\n",
        "levels = 4\n",
        "\n",
        "# LCI params\n",
        "alpha_prob = 0.01\n",
        "\n",
        "# LCI algorithm parameters (bisection)\n",
        "LCI_iters = 200\n",
        "LCI_tol = 1e-4\n",
        "LCI_bottom = -10\n",
        "LCI_top = 10\n",
        "\n",
        "# Compute the MAP-based UQ plots\n",
        "superpix_MAP_sizes = [16, 8]  # [32, 16, 8, 4]\n",
        "# Clipping values for MAP-based LCI. Set as None for no clipping\n",
        "clip_high_val = 1.\n",
        "clip_low_val = 0.\n",
        "\n",
        "# Compute the sampling UQ plots\n",
        "superpix_sizes = [32,16,8,4,1]\n",
        "\n",
        "# Sampling alg params\n",
        "frac_delta = 0.98\n",
        "frac_burnin = 0.1\n",
        "n_samples = np.int64(5e4)\n",
        "thinning = np.int64(1e1)\n",
        "maxit = np.int64(n_samples * thinning * (1. + frac_burnin))\n",
        "# SKROCK params\n",
        "nStages = 10\n",
        "eta = 0.05\n",
        "dt_perc = 0.99\n",
        "\n",
        "# Plot parameters\n",
        "cmap = 'cubehelix'\n",
        "nLags = 100\n",
        "\n",
        "\n",
        "# Img name list\n",
        "img_name_list = ['W28']  # ['M31', 'W28', 'CYN', '3c288']\n",
        "# Input noise level\n",
        "input_snr = 30.\n",
        "\n",
        "\n",
        "save_fig_vals = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold:  0.002599902946466276\n",
            "Running Base Forward Backward\n",
            "[Forward Backward] 0 out of 15000 iterations, tol = 5.18e-01\n",
            "[Forward Backward] converged in 207 iterations\n",
            "Dirty\n",
            "(PSNR: 32.25,\n",
            " SNR: 3.39, SSIM: 0.58)\n",
            "Reconstruction\n",
            "(PSNR: 49.35,\n",
            " SNR: 20.49, SSIM: 0.99)\n",
            "Residual (x - x^hat)\n",
            "(PSNR: 29.07,\n",
            " SNR: 0.21, SSIM: 0.93)\n",
            "Calculating credible interval for superpxiel:  (256, 256)\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "Calculating credible interval for superpxiel:  (256, 256)\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "f(x_map):  10271.531836240363 \n",
            "g(x_map):  111710.79112537045 \n",
            "tau_alpha*np.sqrt(N):  2445.577521189034 \n",
            "N:  65536\n",
            "tau_alpha:  9.553037192144664\n",
            "gamma_alpha:  189963.90048279986\n"
          ]
        }
      ],
      "source": [
        "for img_name in img_name_list:\n",
        "\n",
        "    optim_iters = []\n",
        "    lci_uq_iters_arr = []\n",
        "\n",
        "    # %%\n",
        "    # Load image and mask\n",
        "    img, mat_mask = luq.helpers.load_imgs(img_name, repo_dir)\n",
        "\n",
        "    # Aliases\n",
        "    x = img\n",
        "    ground_truth = img\n",
        "\n",
        "    torch_img = torch.tensor(\n",
        "        np.copy(img), dtype=myType, device=device).reshape((1,1) + img.shape\n",
        "    )\n",
        "\n",
        "    phi = luq.operators.MaskedFourier_torch(\n",
        "        shape=img.shape, \n",
        "        ratio=0.5 ,\n",
        "        mask=mat_mask,\n",
        "        norm='ortho',\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    y = phi.dir_op(torch_img).detach().cpu().squeeze().numpy()\n",
        "\n",
        "    # Define X Cai noise level\n",
        "    eff_sigma = luq.helpers.compute_complex_sigma_noise(y, input_snr)\n",
        "    sigma = eff_sigma * np.sqrt(2)\n",
        "\n",
        "    # Generate noise\n",
        "    rng = np.random.default_rng(seed=0)\n",
        "    n_re = rng.normal(0, eff_sigma, y[y!=0].shape)\n",
        "    n_im = rng.normal(0, eff_sigma, y[y!=0].shape)\n",
        "    # Add noise\n",
        "    y[y!=0] += (n_re + 1.j*n_im)\n",
        "\n",
        "    # Observation\n",
        "    torch_y = torch.tensor(np.copy(y), device=device, dtype=myComplexType).reshape((1,) + img.shape)\n",
        "    x_init = torch.abs(phi.adj_op(torch_y))\n",
        "\n",
        "\n",
        "    # %%\n",
        "    # Define the likelihood\n",
        "    g = luq.operators.L2Norm_torch(\n",
        "        sigma=sigma,\n",
        "        data=torch_y,\n",
        "        Phi=phi,\n",
        "    )\n",
        "    # Lipschitz constant computed automatically by g, stored in g.beta\n",
        "\n",
        "    # Define real prox\n",
        "    f = luq.operators.RealProx_torch()\n",
        "\n",
        "    # %%\n",
        "\n",
        "    for it_1 in range(len(reg_params)):\n",
        "\n",
        "        # Prior parameters\n",
        "        reg_param = reg_params[it_1]\n",
        "\n",
        "        # Define the wavelet dict\n",
        "        # Define the l1 norm with dict psi\n",
        "        psi = luq.operators.DictionaryWv_torch(wavs_list, levels)\n",
        "        h = luq.operators.L1Norm_torch(1., psi, op_to_coeffs=True)\n",
        "        h.gamma = reg_param\n",
        "\n",
        "        # Compute stepsize\n",
        "        alpha = 0.98 / g.beta\n",
        "\n",
        "        # Effective threshold\n",
        "        print('Threshold: ', h.gamma * alpha)\n",
        "\n",
        "        # Run the optimisation\n",
        "        x_hat, diagnostics = luq.optim.FB_torch(\n",
        "            x_init,\n",
        "            options=options,\n",
        "            g=g,\n",
        "            f=f,\n",
        "            h=h,\n",
        "            alpha=alpha,\n",
        "            tau=alpha,\n",
        "            viewer=None\n",
        "        )\n",
        "\n",
        "        # %%\n",
        "        np_x_init = to_numpy(x_init)\n",
        "        np_x = np.copy(x)\n",
        "        np_x_hat = to_numpy(x_hat)\n",
        "\n",
        "\n",
        "        # %%\n",
        "        images = [np_x, np_x_init, np_x_hat, np_x - np.abs(np_x_hat)]\n",
        "        labels = [\"Truth\", \"Dirty\", \"Reconstruction\", \"Residual (x - x^hat)\"]\n",
        "        fig, axs = plt.subplots(1,4, figsize=(24,6), dpi=200)\n",
        "        for i in range(4):\n",
        "            im = axs[i].imshow(images[i], cmap='cubehelix', vmax=np.nanmax(images[i]), vmin=np.nanmin(images[i]))\n",
        "            divider = make_axes_locatable(axs[i])\n",
        "            cax = divider.append_axes('right', size='5%', pad=0.05)\n",
        "            fig.colorbar(im, cax=cax, orientation='vertical')\n",
        "            if i > 0:   \n",
        "                stats_str = '\\n(PSNR: {},\\n SNR: {}, SSIM: {})'.format(\n",
        "                    round(psnr(ground_truth, images[i], data_range=ground_truth.max()-ground_truth.min()), 2),\n",
        "                    round(luq.utils.eval_snr(x, images[i]), 2),\n",
        "                    round(ssim(ground_truth, images[i], data_range=ground_truth.max()-ground_truth.min()), 2),\n",
        "                    )\n",
        "                labels[i] += stats_str\n",
        "                print(labels[i])\n",
        "            axs[i].set_title(labels[i], fontsize=16)\n",
        "            axs[i].axis('off')\n",
        "        # plt.savefig('{:s}{:s}_SKROCK_wavelets_reg_param_{:.1e}_optim_MAP.pdf'.format(savefig_dir, img_name, reg_param))\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "        ### MAP-based UQ\n",
        "\n",
        "        # Define prior potential\n",
        "        fun_prior = lambda _x : h._fun_coeffs(h.dir_op(_x))\n",
        "        # Define posterior potential\n",
        "        loss_fun_torch = lambda _x : g.fun(_x) +  fun_prior(_x)\n",
        "        # Numpy version of the posterior potential\n",
        "        loss_fun_np = lambda _x : g.fun(\n",
        "            luq.utils.to_tensor(_x, dtype=myType)\n",
        "        ).item() +  fun_prior(luq.utils.to_tensor(_x, dtype=myType)).item()\n",
        "\n",
        "        # Compute HPD region bound\n",
        "        N = np_x_hat.size\n",
        "        tau_alpha = np.sqrt(16*np.log(3/alpha_prob))\n",
        "        gamma_alpha = loss_fun_torch(x_hat).item() + tau_alpha*np.sqrt(N) + N\n",
        "\n",
        "\n",
        "        # Compute the LCI\n",
        "        error_p_arr = []\n",
        "        error_m_arr = []\n",
        "        mean_img_arr = []\n",
        "        computing_time = []\n",
        "\n",
        "        x_init_np = luq.utils.to_numpy(x_init)\n",
        "\n",
        "        # Compute ground truth block \n",
        "        gt_mean_img_arr = []\n",
        "        for superpix_size in superpix_MAP_sizes:\n",
        "            mean_image = ski.measure.block_reduce(\n",
        "                np.copy(img), block_size=(superpix_size, superpix_size), func=np.mean\n",
        "            )\n",
        "            gt_mean_img_arr.append(mean_image)\n",
        "\n",
        "        # Define prefix\n",
        "        save_MAP_prefix = '{:s}_wavelets_UQ_MAP_reg_param_{:.1e}'.format(img_name, reg_param)\n",
        "\n",
        "        for it_pixs, superpix_size in enumerate(superpix_MAP_sizes):\n",
        "\n",
        "            pr_time_1 = time.process_time()\n",
        "            wall_time_1 = time.time()\n",
        "\n",
        "            error_p, error_m, mean, lci_iters_cumul = luq.map_uncertainty.create_local_credible_interval(\n",
        "                x_sol=np_x_hat,\n",
        "                region_size=superpix_size,\n",
        "                function=loss_fun_np,\n",
        "                bound=gamma_alpha,\n",
        "                iters=LCI_iters,\n",
        "                tol=LCI_tol,\n",
        "                bottom=LCI_bottom,\n",
        "                top=LCI_top,\n",
        "                return_iters=True,\n",
        "            )\n",
        "            pr_time_2 = time.process_time()\n",
        "            wall_time_2 = time.time()\n",
        "\n",
        "            # Save iteration number\n",
        "            lci_uq_iters_arr.append(lci_iters_cumul)\n",
        "\n",
        "            # Add values to array to save it later\n",
        "            error_p_arr.append(np.copy(error_p))\n",
        "            error_m_arr.append(np.copy(error_m))\n",
        "            mean_img_arr.append(np.copy(mean))\n",
        "            computing_time.append((\n",
        "                pr_time_2 - pr_time_1, \n",
        "                wall_time_2 - wall_time_1\n",
        "            ))\n",
        "            # Clip plot values\n",
        "            error_length = luq.utils.clip_matrix(\n",
        "                np.copy(error_p), clip_low_val, clip_high_val\n",
        "            ) - luq.utils.clip_matrix(\n",
        "                np.copy(error_m), clip_low_val, clip_high_val\n",
        "            )\n",
        "            # Recover the ground truth mean\n",
        "            gt_mean = gt_mean_img_arr[it_pixs]\n",
        "\n",
        "            vmin = np.min((gt_mean, mean, error_length))\n",
        "            vmax = np.max((gt_mean, mean, error_length))\n",
        "\n",
        "            # Plot UQ\n",
        "            fig = plt.figure(figsize=(24,5))\n",
        "\n",
        "            plt.subplot(141)\n",
        "            ax = plt.gca()\n",
        "            ax.set_title('MAP estimation,\\n superpix = {:d}'.format(superpix_size))\n",
        "            im = ax.imshow(mean, cmap=cmap, vmin=vmin, vmax=vmax)\n",
        "            divider = make_axes_locatable(ax)\n",
        "            cax = divider.append_axes('right', size='5%', pad=0.05)\n",
        "            fig.colorbar(im, cax=cax, orientation='vertical')\n",
        "            ax.set_yticks([]);ax.set_xticks([])\n",
        "\n",
        "            plt.subplot(142)\n",
        "            ax = plt.gca()\n",
        "            ax.set_title(\n",
        "                'Residual (GT - MAP),\\n RMSE = {:.3e}'.format(\n",
        "                    np.sqrt(np.sum((gt_mean - mean)**2))\n",
        "                )\n",
        "            )\n",
        "            im = ax.imshow(gt_mean - mean, cmap=cmap)\n",
        "            divider = make_axes_locatable(ax)\n",
        "            cax = divider.append_axes('right', size='5%', pad=0.05)\n",
        "            fig.colorbar(im, cax=cax, orientation='vertical')\n",
        "            ax.set_yticks([]);ax.set_xticks([])\n",
        "\n",
        "            plt.subplot(143)\n",
        "            ax = plt.gca()\n",
        "            ax.set_title('LCI (max={:.5f})\\n (<LCI>={:.5f})'.format(\n",
        "                    np.max(error_length), np.mean(error_length)\n",
        "                )\n",
        "            )\n",
        "            im = ax.imshow(error_length, cmap=cmap, vmin=vmin, vmax=vmax)\n",
        "            divider = make_axes_locatable(ax)\n",
        "            cax = divider.append_axes('right', size='5%', pad=0.05)\n",
        "            fig.colorbar(im, cax=cax, orientation='vertical')\n",
        "            ax.set_yticks([]);ax.set_xticks([])\n",
        "\n",
        "            plt.subplot(144)\n",
        "            ax = plt.gca()\n",
        "            ax.set_title('LCI - min(LCI)')\n",
        "            im = ax.imshow(error_length - np.min(error_length), cmap=cmap, vmin=vmin, vmax=vmax)\n",
        "            divider = make_axes_locatable(ax)\n",
        "            cax = divider.append_axes('right', size='5%', pad=0.05)\n",
        "            fig.colorbar(im, cax=cax, orientation='vertical')\n",
        "            ax.set_yticks([]);ax.set_xticks([])\n",
        "\n",
        "            # plt.savefig(\n",
        "            #     savefig_dir+save_MAP_prefix+'_UQ-MAP_pixel_size_{:d}.pdf'.format(superpix_size)\n",
        "            # )\n",
        "            plt.close()\n",
        "\n",
        "\n",
        "        print(\n",
        "            'f(x_map): ', g.fun(x_hat).item(),\n",
        "            '\\ng(x_map): ', fun_prior(x_hat).item(),\n",
        "            '\\ntau_alpha*np.sqrt(N): ', tau_alpha*np.sqrt(N),\n",
        "            '\\nN: ', N,\n",
        "        )\n",
        "        print('tau_alpha: ', tau_alpha)\n",
        "        print('gamma_alpha: ', gamma_alpha.item())\n",
        "        # \n",
        "        opt_params = {\n",
        "            'wav': wavs_list,\n",
        "            'levels': levels,\n",
        "            'reg_param': reg_param,\n",
        "            'sigma_noise': sigma,\n",
        "            'opt_tol': options['tol'],\n",
        "            'opt_max_iter': options['iter'],\n",
        "        }\n",
        "        hpd_results = {\n",
        "            'alpha': alpha_prob,\n",
        "            'gamma_alpha': gamma_alpha,\n",
        "            'f_xmap': g.fun(x_hat).item(),\n",
        "            'g_xmap': fun_prior(x_hat).item(),\n",
        "            'h_alpha_N': tau_alpha*np.sqrt(N) + N,\n",
        "        }\n",
        "        LCI_params ={\n",
        "            'iters': LCI_iters,\n",
        "            'tol': LCI_tol,\n",
        "            'bottom': LCI_bottom,\n",
        "            'top': LCI_top,\n",
        "            'top': LCI_top,\n",
        "            'clip_low_val': clip_low_val,\n",
        "            'clip_high_val': clip_high_val,\n",
        "        }\n",
        "        save_map_vars = {\n",
        "            'x_ground_truth': img,\n",
        "            'x_map': np_x_hat,\n",
        "            'x_init': np_x_init,\n",
        "            'opt_params': opt_params,\n",
        "            'hpd_results': hpd_results,\n",
        "            'error_p_arr': error_p_arr,\n",
        "            'error_m_arr': error_m_arr,\n",
        "            'mean_img_arr': mean_img_arr,\n",
        "            'gt_mean_img_arr': gt_mean_img_arr,\n",
        "            'computing_time': computing_time,\n",
        "            'superpix_sizes': superpix_MAP_sizes,\n",
        "            'LCI_params': LCI_params,\n",
        "        }\n",
        "        # We will overwrite the dict with new results\n",
        "        # try:\n",
        "        #     saving_map_path = save_dir + save_MAP_prefix + '_MAP_vars.npy'\n",
        "        #     if os.path.isfile(saving_map_path):\n",
        "        #         os.remove(saving_map_path)\n",
        "        #     np.save(saving_map_path, save_map_vars, allow_pickle=True)\n",
        "        # except Exception as e:\n",
        "        #     print('Could not save vairables. Exception caught: ', e)    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration number for W28\n",
            "LCI iterations 16x16 super pixe:  21202\n",
            "LCI iterations 8x8 super pixe:  81576\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "print('Iteration number for W28')\n",
        "\n",
        "# print('Optimisation iterations: ', optim_iters[0])\n",
        "print('LCI iterations 16x16 super pixe: ', lci_uq_iters_arr[0])\n",
        "print('LCI iterations 8x8 super pixe: ', lci_uq_iters_arr[1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "convex_uq",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "2bb75ebd6ceb1eff2ce987e124c91bc6f99e62fd1930d98a82dc138614104eef"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
