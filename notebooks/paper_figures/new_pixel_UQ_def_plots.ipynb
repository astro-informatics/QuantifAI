{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "1\n",
            "0\n",
            "NVIDIA A100-PCIE-40GB\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import time as time\n",
        "\n",
        "import torch\n",
        "M1 = False\n",
        "\n",
        "if M1:\n",
        "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "else:\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    if torch.cuda.is_available():\n",
        "        print(torch.cuda.is_available())\n",
        "        print(torch.cuda.device_count())\n",
        "        print(torch.cuda.current_device())\n",
        "        print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
        "\n",
        "\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from torchmetrics.functional import structural_similarity_index_measure \n",
        "from torchmetrics.functional import peak_signal_noise_ratio \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib.ticker as tick\n",
        "\n",
        "import scipy.io as sio\n",
        "from astropy.io import fits\n",
        "import skimage as ski\n",
        "\n",
        "import large_scale_UQ as luq\n",
        "from large_scale_UQ.utils import to_numpy, to_tensor\n",
        "from convex_reg import utils as utils_cvx_reg\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "repo_dir = '/disk/xray0/tl3/repos/large-scale-UQ'\n",
        "CRR_save_dir = '/disk/xray0/tl3/outputs/large-scale-UQ/def_UQ_results/CRR/new_pixel_UQ/'\n",
        "wav_save_dir = '/disk/xray0/tl3/outputs/large-scale-UQ/def_UQ_results/wavelets/paper_figs_new_UQ/'\n",
        "load_var_dir = '/disk/xray0/tl3/outputs/large-scale-UQ/def_UQ_results/CRR/vars/'\n",
        "wav_load_var_dir = '/disk/xray0/tl3/outputs/large-scale-UQ/def_UQ_results/wavelets/vars/'\n",
        "\n",
        "cmap = 'cubehelix'\n",
        "cbar_font_size = 18\n",
        "\n",
        "map_vars_path_arr = [\n",
        "    load_var_dir+'CYN_CRR_UQ_MAP_lmbd_5.0e+04_MAP_vars.npy',\n",
        "    load_var_dir+'M31_CRR_UQ_MAP_lmbd_5.0e+04_MAP_vars.npy',\n",
        "    load_var_dir+'3c288_CRR_UQ_MAP_lmbd_5.0e+04_MAP_vars.npy',\n",
        "    load_var_dir+'W28_CRR_UQ_MAP_lmbd_5.0e+04_MAP_vars.npy',\n",
        "]\n",
        "samp_vars_path_arr = [\n",
        "    load_var_dir+'CYN_SKROCK_CRR_lmbd_5.0e+04_mu_2.0e+01_nsamples_5.0e+04_thinning_1.0e+01_vars.npy',\n",
        "    load_var_dir+'M31_SKROCK_CRR_lmbd_5.0e+04_mu_2.0e+01_nsamples_5.0e+04_thinning_1.0e+01_vars.npy',\n",
        "    load_var_dir+'3c288_SKROCK_CRR_lmbd_5.0e+04_mu_2.0e+01_nsamples_5.0e+04_thinning_1.0e+01_vars.npy',\n",
        "    load_var_dir+'W28_SKROCK_CRR_lmbd_5.0e+04_mu_2.0e+01_nsamples_5.0e+04_thinning_1.0e+01_vars.npy',    \n",
        "]\n",
        "\n",
        "img_name_arr = [\n",
        "    'CYN',\n",
        "    'M31',\n",
        "    '3c288',\n",
        "    'W28',\n",
        "]\n",
        "vmin_log_arr = [\n",
        "    -3.,\n",
        "    -2.,\n",
        "    -2.,\n",
        "    -2.,\n",
        "]\n",
        "\n",
        "options = {\"tol\": 1e-5, \"iter\": 15000, \"update_iter\": 4999, \"record_iters\": False}\n",
        "\n",
        "# CRR load parameters\n",
        "sigma_training = 5\n",
        "t_model = 5\n",
        "CRR_dir_name = '/disk/xray0/tl3/repos/convex_ridge_regularizers/trained_models/'\n",
        "# CRR parameters\n",
        "reg_param = 5e4\n",
        "mu = 20\n",
        "\n",
        "# Define my torch types (CRR requires torch.float32)\n",
        "myType = torch.float32\n",
        "myComplexType = torch.complex64\n",
        "\n",
        "# Parameters\n",
        "alpha_prob = 0.01\n",
        "\n",
        "# Define the wavelet parameters for UQ maps\n",
        "wavs_list = ['db8']\n",
        "levels = 4\n",
        "# Parameters for UQ map\n",
        "start_interval = [0, 10]\n",
        "iters = 5e2\n",
        "tol = 1e-2\n",
        "\n",
        "model_prefix = '-CRR'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "for it in range(len(img_name_arr)):\n",
        "    # Set paths\n",
        "    if model_prefix == '-CRR':\n",
        "        img_name = img_name_arr[it]\n",
        "        # map_vars_path = map_vars_path_arr[it]\n",
        "        # samp_vars_path = samp_vars_path_arr[it]\n",
        "        vmin_log = vmin_log_arr[it]\n",
        "        save_dir = CRR_save_dir\n",
        "        save_var_dir = load_var_dir\n",
        "\n",
        "\n",
        "    # Load image and mask\n",
        "    img, mat_mask = luq.helpers.load_imgs(img_name, repo_dir)\n",
        "    # Aliases\n",
        "    x = img\n",
        "    ground_truth = img\n",
        "    # Convert Torch\n",
        "    torch_img = torch.tensor(\n",
        "        np.copy(img), dtype=myType, device=device).reshape((1,1) + img.shape\n",
        "    )\n",
        "    # Init Fourier masl op\n",
        "    phi = luq.operators.MaskedFourier_torch(\n",
        "        shape=img.shape, \n",
        "        ratio=0.5 ,\n",
        "        mask=mat_mask,\n",
        "        norm='ortho',\n",
        "        device=device\n",
        "    )\n",
        "    # Define X Cai noise level\n",
        "    sigma = 0.0024\n",
        "    y = phi.dir_op(torch_img).detach().cpu().squeeze().numpy()\n",
        "    # Generate noise\n",
        "    rng = np.random.default_rng(seed=0)\n",
        "    n = rng.normal(0, sigma, y[y!=0].shape)\n",
        "    # Add noise\n",
        "    y[y!=0] += n\n",
        "    # Observation\n",
        "    torch_y = torch.tensor(np.copy(y), device=device, dtype=myComplexType).reshape((1,) + img.shape)\n",
        "    x_init = torch.abs(phi.adj_op(torch_y))\n",
        "    # Define the likelihood\n",
        "    g = luq.operators.L2Norm_torch(\n",
        "        sigma=sigma,\n",
        "        data=torch_y,\n",
        "        Phi=phi,\n",
        "    )\n",
        "    # Lipschitz constant computed automatically by g, stored in g.beta\n",
        "    # Define real prox\n",
        "    f = luq.operators.RealProx_torch()\n",
        "\n",
        "\n",
        "    # Load CRR model\n",
        "    torch.set_grad_enabled(False)\n",
        "    torch.set_num_threads(4)\n",
        "\n",
        "    exp_name = f'Sigma_{sigma_training}_t_{t_model}/'\n",
        "    model = utils_cvx_reg.load_model(CRR_dir_name + exp_name, 'cuda:0', device_type='gpu')\n",
        "\n",
        "    print(f'Numbers of parameters before prunning: {model.num_params}')\n",
        "    model.prune()\n",
        "    print(f'Numbers of parameters after prunning: {model.num_params}')\n",
        "\n",
        "    # L_CRR = model.L.detach().cpu().squeeze().numpy()\n",
        "    # print(f\"Lipschitz bound {L_CRR:.3f}\")\n",
        "\n",
        "    # [not required] intialize the eigen vector of dimension (size, size) associated to the largest eigen value\n",
        "    model.initializeEigen(size=100)\n",
        "    # compute bound via a power iteration which couples the activations and the convolutions\n",
        "    model.precise_lipschitz_bound(n_iter=100)\n",
        "    # the bound is stored in the model\n",
        "    L_CRR = model.L.data.item()\n",
        "    print(f\"Lipschitz bound {L_CRR:.3f}\")\n",
        "    \n",
        "\n",
        "    ## Compute MAP solution\n",
        "    # Prior parameters\n",
        "    lmbd = reg_param\n",
        "\n",
        "    # Compute stepsize\n",
        "    alpha = 0.98 / (g.beta + mu * lmbd * L_CRR)\n",
        "\n",
        "    # initialization\n",
        "    x_hat = torch.clone(x_init)\n",
        "    z = torch.clone(x_init)\n",
        "    t = 1\n",
        "\n",
        "    # Accelerated gradient descend\n",
        "    for it_2 in range(options['iter']):\n",
        "        x_hat_old = torch.clone(x_hat)\n",
        "        \n",
        "        x_hat = z - alpha *(\n",
        "            g.grad(z) + lmbd * model(mu * z)\n",
        "        )\n",
        "        # Reality constraint\n",
        "        x_hat = f.prox(x_hat)\n",
        "        \n",
        "        t_old = t \n",
        "        t = 0.5 * (1 + math.sqrt(1 + 4*t**2))\n",
        "        z = x_hat + (t_old - 1)/t * (x_hat - x_hat_old)\n",
        "\n",
        "        # relative change of norm for terminating\n",
        "        res = (torch.norm(x_hat_old - x_hat)/torch.norm(x_hat_old)).item()\n",
        "\n",
        "        if res < options['tol']:\n",
        "            print(\"[GD] converged in %d iterations\"%(it_2))\n",
        "            break\n",
        "\n",
        "        if it_2 % options['update_iter'] == 0:\n",
        "            print(\n",
        "                \"[GD] %d out of %d iterations, tol = %f\" %(            \n",
        "                    it_2,\n",
        "                    options['iter'],\n",
        "                    res,\n",
        "                )\n",
        "            )\n",
        "\n",
        "\n",
        "    # Save MAP\n",
        "    np_x_hat = to_numpy(x_hat)\n",
        "    np_x = np.copy(x)\n",
        "    # Evaluate performance\n",
        "    print(img_name, ' PSNR: ', psnr(np_x, np_x_hat, data_range=np_x.max()-np_x.min()))\n",
        "    print(img_name, ' SNR: ', luq.utils.eval_snr(x, np_x_hat))\n",
        "\n",
        "\n",
        "    # Function handle for the potential\n",
        "    def _fun(_x, model, mu, lmbd):\n",
        "        return (lmbd / mu) * model.cost(mu * _x) + g.fun(_x)\n",
        "\n",
        "    # Evaluation of the potential\n",
        "    fun = partial(_fun, model=model, mu=mu, lmbd=lmbd)\n",
        "    # Evaluation of the potential in numpy\n",
        "    fun_np = lambda _x : fun(luq.utils.to_tensor(_x, dtype=myType)).item()\n",
        "\n",
        "    # Compute HPD region bound\n",
        "    N = np_x_hat.size\n",
        "    tau_alpha = np.sqrt(16*np.log(3/alpha_prob))\n",
        "    gamma_alpha = fun(x_hat).item() + tau_alpha*np.sqrt(N) + N\n",
        "\n",
        "    \n",
        "    # Define the wavelet dict\n",
        "    # Define the l1 norm with dict psi\n",
        "    Psi = luq.operators.DictionaryWv_torch(wavs_list, levels)\n",
        "    oper2wavelet = luq.operators.Operation2WaveletCoeffs_torch(Psi=Psi)\n",
        "\n",
        "    # Clone MAP estimation and cast type for wavelet operations\n",
        "    torch_map = torch.clone(x_hat).to(torch.float64)\n",
        "    torch_x = to_tensor(np_x).to(torch.float64)\n",
        "\n",
        "    \n",
        "    def _potential_to_bisect(thresh, fun_np, oper2wavelet, torch_map):\n",
        "\n",
        "        thresh_img = oper2wavelet.full_op_threshold_img(torch_map, thresh)\n",
        "\n",
        "        return gamma_alpha - fun_np(thresh_img)\n",
        "\n",
        "    # Evaluation of the potential\n",
        "    potential_to_bisect = partial(\n",
        "        _potential_to_bisect,\n",
        "        fun_np=fun_np,\n",
        "        oper2wavelet=oper2wavelet,\n",
        "        torch_map=torch_map\n",
        "    )\n",
        "\n",
        "\n",
        "    selected_thresh = luq.map_uncertainty.bisection_method(\n",
        "        potential_to_bisect, start_interval, iters, tol\n",
        "    )\n",
        "    select_thresh_img = oper2wavelet.full_op_threshold_img(\n",
        "        torch_map, selected_thresh\n",
        "    )\n",
        "    print('selected_thresh: ', selected_thresh)\n",
        "    print('gamma_alpha: ', gamma_alpha)\n",
        "    print('MAP image: ', fun_np(torch_map.squeeze()))\n",
        "    print('thresholded image: ', fun_np(select_thresh_img))\n",
        "\n",
        "    # Plot MAP\n",
        "    fig = plt.figure(figsize=(5,5), dpi=200)\n",
        "    axs = plt.gca()\n",
        "    im_log = np.log10(np.abs(np_x_hat))\n",
        "    plt_im = axs.imshow(im_log, cmap=cmap, vmin=vmin_log, vmax=0)\n",
        "    divider = make_axes_locatable(axs)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    cbar = fig.colorbar(plt_im, cax=cax)\n",
        "    cbar.ax.yaxis.set_major_formatter(tick.FormatStrFormatter('%.2f'))\n",
        "    cbar.ax.tick_params(labelsize=cbar_font_size)\n",
        "    axs.set_yticks([]);axs.set_xticks([])\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\n",
        "        '{:s}{:s}{:s}{:s}'.format(\n",
        "            save_dir, img_name, model_prefix, '-newPixelUQ-MAP.pdf'\n",
        "        ),\n",
        "        bbox_inches='tight',\n",
        "        dpi=200\n",
        "    )\n",
        "    plt.show()\n",
        "\n",
        "    # Plot Thresholded image\n",
        "    fig = plt.figure(figsize=(5,5), dpi=200)\n",
        "    axs = plt.gca()\n",
        "    im_log = np.log10(np.abs(to_numpy(select_thresh_img)))\n",
        "    plt_im = axs.imshow(im_log, cmap=cmap, vmin=vmin_log, vmax=0)\n",
        "    divider = make_axes_locatable(axs)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    cbar = fig.colorbar(plt_im, cax=cax)\n",
        "    cbar.ax.yaxis.set_major_formatter(tick.FormatStrFormatter('%.2f'))\n",
        "    cbar.ax.tick_params(labelsize=cbar_font_size)\n",
        "    axs.set_yticks([]);axs.set_xticks([])\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\n",
        "        '{:s}{:s}{:s}{:s}'.format(\n",
        "            save_dir, img_name, model_prefix, '-newPixelUQ-ThresholdedImage.pdf'\n",
        "        ),\n",
        "        bbox_inches='tight',\n",
        "        dpi=200\n",
        "    )\n",
        "    plt.show()\n",
        "\n",
        "    # Plot MAP - Thresholded error\n",
        "    fig = plt.figure(figsize=(5,5), dpi=200)\n",
        "    axs = plt.gca()\n",
        "    im_log = np.log10(np.abs(to_numpy(torch_map - select_thresh_img)))\n",
        "    plt_im = axs.imshow(im_log, cmap=cmap, vmin=vmin_log-2, vmax=0)\n",
        "    divider = make_axes_locatable(axs)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    cbar = fig.colorbar(plt_im, cax=cax)\n",
        "    cbar.ax.yaxis.set_major_formatter(tick.FormatStrFormatter('%.2f'))\n",
        "    cbar.ax.tick_params(labelsize=cbar_font_size)\n",
        "    axs.set_yticks([]);axs.set_xticks([])\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\n",
        "        '{:s}{:s}{:s}{:s}'.format(\n",
        "            save_dir, img_name, model_prefix, '-newPixelUQ-MAP_thresholded_error.pdf'\n",
        "        ),\n",
        "        bbox_inches='tight',\n",
        "        dpi=200\n",
        "    )\n",
        "    plt.show()\n",
        "\n",
        "    # Plot MAP - Thresholded error\n",
        "    fig = plt.figure(figsize=(5,5), dpi=200)\n",
        "    axs = plt.gca()\n",
        "    im_log = np.log10(np.abs(np_x - np_x_hat))\n",
        "    plt_im = axs.imshow(im_log, cmap=cmap, vmin=vmin_log-2, vmax=0)\n",
        "    divider = make_axes_locatable(axs)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    cbar = fig.colorbar(plt_im, cax=cax)\n",
        "    cbar.ax.yaxis.set_major_formatter(tick.FormatStrFormatter('%.2f'))\n",
        "    cbar.ax.tick_params(labelsize=cbar_font_size)\n",
        "    axs.set_yticks([]);axs.set_xticks([])\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\n",
        "        '{:s}{:s}{:s}{:s}'.format(\n",
        "            save_dir, img_name, model_prefix, '-newPixelUQ-GT_MAP_error.pdf'\n",
        "        ),\n",
        "        bbox_inches='tight',\n",
        "        dpi=200\n",
        "    )\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    modif_img_list = []\n",
        "    GT_modif_img_list = []\n",
        "    SNR_at_lvl_list = []\n",
        "\n",
        "    for modif_level in range(levels+1):\n",
        "\n",
        "        op = lambda x1, x2: x2\n",
        "\n",
        "        modif_img = oper2wavelet.full_op_two_img(\n",
        "            torch.clone(torch_map),\n",
        "            torch.clone(select_thresh_img),\n",
        "            op,\n",
        "            level=modif_level\n",
        "        )\n",
        "        GT_modif_img = oper2wavelet.full_op_two_img(\n",
        "            torch.clone(torch_x),\n",
        "            torch.clone(torch_map),\n",
        "            op,\n",
        "            level=modif_level\n",
        "        )\n",
        "        print('SNR at lvl {:d}: {:f}'.format(\n",
        "            modif_level, luq.utils.eval_snr(to_numpy(torch_map), to_numpy(modif_img)))\n",
        "        )\n",
        "        modif_img_list.append(to_numpy(modif_img))\n",
        "        GT_modif_img_list.append(to_numpy(GT_modif_img))\n",
        "        SNR_at_lvl_list.append(luq.utils.eval_snr(to_numpy(torch_map), to_numpy(modif_img)))    \n",
        "\n",
        "        # Plot MAP - Thresholded error\n",
        "        fig = plt.figure(figsize=(5,5), dpi=200)\n",
        "        axs = plt.gca()\n",
        "        im_log = np.log10(np.abs(to_numpy(torch_map - modif_img)))\n",
        "        plt_im = axs.imshow(im_log, cmap=cmap, vmin=vmin_log-2, vmax=0)\n",
        "        divider = make_axes_locatable(axs)\n",
        "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "        cbar = fig.colorbar(plt_im, cax=cax)\n",
        "        cbar.ax.yaxis.set_major_formatter(tick.FormatStrFormatter('%.2f'))\n",
        "        cbar.ax.tick_params(labelsize=cbar_font_size)\n",
        "        axs.set_yticks([]);axs.set_xticks([])\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\n",
        "            '{:s}{:s}{:s}{:s}{:d}{:s}'.format(\n",
        "                save_dir,\n",
        "                img_name,\n",
        "                model_prefix,\n",
        "                '-newPixelUQ-MAP_thresholded_error_level_',\n",
        "                modif_level,\n",
        "                '.pdf'\n",
        "            ),\n",
        "            bbox_inches='tight',\n",
        "            dpi=200\n",
        "        )\n",
        "        plt.show()\n",
        "\n",
        "        # Plot GT - MAP error\n",
        "        fig = plt.figure(figsize=(5,5), dpi=200)\n",
        "        axs = plt.gca()\n",
        "        im_log = np.log10(np.abs(np_x - to_numpy(GT_modif_img)))\n",
        "        plt_im = axs.imshow(im_log, cmap=cmap, vmin=vmin_log-2, vmax=0)\n",
        "        divider = make_axes_locatable(axs)\n",
        "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "        cbar = fig.colorbar(plt_im, cax=cax)\n",
        "        cbar.ax.yaxis.set_major_formatter(tick.FormatStrFormatter('%.2f'))\n",
        "        cbar.ax.tick_params(labelsize=cbar_font_size)\n",
        "        axs.set_yticks([]);axs.set_xticks([])\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\n",
        "            '{:s}{:s}{:s}{:s}{:d}{:s}'.format(\n",
        "                save_dir,\n",
        "                img_name,\n",
        "                model_prefix,\n",
        "                '-newPixelUQ-GT_MAP_error_level_',\n",
        "                modif_level,\n",
        "                '.pdf'\n",
        "            ),\n",
        "            bbox_inches='tight',\n",
        "            dpi=200\n",
        "        )\n",
        "        plt.show()\n",
        "\n",
        "    config_dict = {\n",
        "        'sigma_training': sigma_training,\n",
        "        't_model': t_model,\n",
        "        'reg_param': reg_param,\n",
        "        'mu': mu,\n",
        "        'alpha_prob': alpha_prob,\n",
        "        'wavs_list': wavs_list,\n",
        "        'levels': levels,\n",
        "        'start_interval': start_interval,\n",
        "        'iters': iters,\n",
        "        'tol': tol,\n",
        "        'optim_options': options,\n",
        "    }\n",
        "    save_dict = {\n",
        "        'gt': np_x,\n",
        "        'map': np_x_hat,\n",
        "        'thresholded_img': to_numpy(select_thresh_img),\n",
        "        'map_thresh_error_at_level': np.array(modif_img_list),\n",
        "        'gt_map_error_at_level': np.array(GT_modif_img_list),\n",
        "        'SNR_at_level': np.array(SNR_at_lvl_list),\n",
        "        'config_dict': config_dict,\n",
        "    }\n",
        "\n",
        "    # We will overwrite the dict with new results\n",
        "    try:\n",
        "        saving_var_path = '{:s}{:s}{:s}{:s}'.format(\n",
        "                save_var_dir,\n",
        "                img_name,\n",
        "                model_prefix,\n",
        "                '-new_pixel_UQ_vars.npy',\n",
        "            )\n",
        "        if os.path.isfile(saving_var_path):\n",
        "            os.remove(saving_var_path)\n",
        "        np.save(saving_var_path, save_dict, allow_pickle=True)\n",
        "    except Exception as e:\n",
        "        print('Could not save vairables. Exception caught: ', e)    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " CYN\n",
            "SNR (MAP wrt GT): \t\t 28.13\n",
            "SNR (thresholded wrt MAP): \t 12.28\n",
            "SNR at lvl 0: \t\t\t15.80\n",
            "SNR at lvl 1: \t\t\t20.07\n",
            "SNR at lvl 2: \t\t\t19.34\n",
            "SNR at lvl 3: \t\t\t20.39\n",
            "SNR at lvl 4: \t\t\t26.14\n",
            "\n",
            "\n",
            " M31\n",
            "SNR (MAP wrt GT): \t\t 32.82\n",
            "SNR (thresholded wrt MAP): \t 22.61\n",
            "SNR at lvl 0: \t\t\t34.17\n",
            "SNR at lvl 1: \t\t\t29.91\n",
            "SNR at lvl 2: \t\t\t26.90\n",
            "SNR at lvl 3: \t\t\t27.20\n",
            "SNR at lvl 4: \t\t\t38.93\n",
            "\n",
            "\n",
            " 3c288\n",
            "SNR (MAP wrt GT): \t\t 25.89\n",
            "SNR (thresholded wrt MAP): \t 23.55\n",
            "SNR at lvl 0: \t\t\t31.88\n",
            "SNR at lvl 1: \t\t\t30.49\n",
            "SNR at lvl 2: \t\t\t27.91\n",
            "SNR at lvl 3: \t\t\t29.44\n",
            "SNR at lvl 4: \t\t\t39.76\n",
            "\n",
            "\n",
            " W28\n",
            "SNR (MAP wrt GT): \t\t 26.59\n",
            "SNR (thresholded wrt MAP): \t 15.57\n",
            "SNR at lvl 0: \t\t\t28.14\n",
            "SNR at lvl 1: \t\t\t23.04\n",
            "SNR at lvl 2: \t\t\t21.21\n",
            "SNR at lvl 3: \t\t\t20.38\n",
            "SNR at lvl 4: \t\t\t23.46\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for it in range(len(img_name_arr)):\n",
        "    # Set paths\n",
        "    if model_prefix == '-CRR':\n",
        "        img_name = img_name_arr[it]\n",
        "        # map_vars_path = map_vars_path_arr[it]\n",
        "        # samp_vars_path = samp_vars_path_arr[it]\n",
        "        # vmin_log = vmin_log_arr[it]\n",
        "        save_dir = CRR_save_dir\n",
        "        save_var_dir = load_var_dir\n",
        "\n",
        "    saving_var_path = '{:s}{:s}{:s}{:s}'.format(\n",
        "        save_var_dir,\n",
        "        img_name,\n",
        "        model_prefix,\n",
        "        '-new_pixel_UQ_vars.npy',\n",
        "    )\n",
        "\n",
        "    data = np.load(saving_var_path, allow_pickle=True)[()]\n",
        "\n",
        "    print('\\n\\n', img_name)\n",
        "    print('SNR (MAP wrt GT): \\t\\t', luq.utils.eval_snr(data['gt'], data['map']))\n",
        "    print('SNR (thresholded wrt MAP): \\t', luq.utils.eval_snr(data['map'], data['thresholded_img']))\n",
        "    for modif_level in range(levels+1):\n",
        "        print('SNR at lvl {:d}: \\t\\t\\t{:.2f}'.format(\n",
        "            modif_level, data['SNR_at_level'][modif_level]\n",
        "        ))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "convex_uq",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "2bb75ebd6ceb1eff2ce987e124c91bc6f99e62fd1930d98a82dc138614104eef"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
