{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "1\n",
            "0\n",
            "NVIDIA A100-PCIE-40GB\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time as time\n",
        "\n",
        "# Import torch and select GPU\n",
        "import torch\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    print(torch.cuda.is_available())\n",
        "    print(torch.cuda.device_count())\n",
        "    print(torch.cuda.current_device())\n",
        "    print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
        "\n",
        "# Plot functions\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "# Radio and convex reg functions\n",
        "import quantifai as qai\n",
        "from quantifai.utils import to_numpy, to_tensor\n",
        "from convex_reg import utils as utils_cvx_reg\n",
        "\n",
        "import skimage as ski\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Optimisation options for the MAP estimation\n",
        "options = {\"tol\": 1e-5, \"iter\": 1500, \"update_iter\": 100, \"record_iters\": False}\n",
        "\n",
        "# Save param\n",
        "repo_dir = \"./../..\"\n",
        "\n",
        "# Test image name from ['M31', 'W28', 'CYN', '3c288']\n",
        "img_name_list = ['M31', 'W28', 'CYN', '3c288']\n",
        "# img_name = \"CYN\"\n",
        "# Input noise level\n",
        "input_snr = 30.0\n",
        "\n",
        "# Define my torch types (CRR requires torch.float32)\n",
        "myType = torch.float64\n",
        "myComplexType = torch.complex128\n",
        "\n",
        "# CRR load parameters\n",
        "sigma_training = 5\n",
        "t_model = 5\n",
        "CRR_dir_name = \"./../../trained_models/\"\n",
        "# CRR parameters\n",
        "lmbd = 5e4  # lambda parameter\n",
        "mu = 20\n",
        "\n",
        "alpha_prob = 0.01\n",
        "\n",
        "wavs_list = [\"db1\", \"db2\", \"db3\", \"db4\", \"db5\", \"db6\", \"db7\", \"db8\", \"self\"]\n",
        "levels = 4\n",
        "# reg_param = 1e2\n",
        "\n",
        "# Compute the MAP-based UQ plots\n",
        "superpix_MAP_sizes = [32, 16, 8, 4]\n",
        "# Clipping values for MAP-based LCI. Set as None for no clipping\n",
        "clip_high_val = 1.0\n",
        "clip_low_val = 0.0\n",
        "\n",
        "# Compute the sampling UQ plots\n",
        "superpix_sizes = [32, 16, 8, 4, 1]\n",
        "\n",
        "# LCI algorithm parameters (bisection)\n",
        "LCI_iters = 200\n",
        "LCI_tol = 1e-4\n",
        "LCI_bottom = -10\n",
        "LCI_top = 10\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "map_potential_list = []\n",
        "gamma_alpha_list = []\n",
        "likelihood_map_potential_list = []\n",
        "prior_map_potential_list = []\n",
        "SNR_list = []\n",
        "PSNR_list = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2.00000000e+01, 2.61939106e+01, 3.43060476e+01, 4.49304772e+01,\n",
              "       5.88452451e+01, 7.70693545e+01, 1.00937389e+02, 1.32197247e+02,\n",
              "       1.73138144e+02, 2.26758253e+02, 2.96984270e+02, 3.88958971e+02,\n",
              "       5.09417825e+02, 6.67182248e+02, 8.73805608e+02, 1.14441930e+03,\n",
              "       1.49884084e+03, 1.96302515e+03, 2.57096526e+03, 3.36718170e+03,\n",
              "       4.40998283e+03, 5.77573479e+03, 7.56445404e+03, 9.90713164e+03,\n",
              "       1.29753260e+04, 1.69937265e+04, 2.22566076e+04, 2.91493795e+04,\n",
              "       3.81768120e+04, 5.00000000e+04])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg_param_list = np.logspace(np.log10(20), np.log10(5e4), num=30, endpoint=True, base=10.0)\n",
        "# reg_param_list[0] = 7e1 \n",
        "# reg_param_list[1] = 8e1 \n",
        "# reg_param_list[2] = 9e1\n",
        "# reg_param_list[3] = 1e2\n",
        "# reg_param_list[4] = 1.1e2\n",
        "# reg_param_list[25] = 1e4\n",
        "\n",
        "reg_param_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: The following header keyword is invalid or follows an unrecognized non-standard convention:\n",
            "INSTRUME                                                                         [astropy.io.fits.card]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running FISTA algorithm\n",
            "[Forward Backward] 0 out of 1500 iterations, tol = 4.02e-01\n",
            "[Forward Backward] 100 out of 1500 iterations, tol = 2.25e-05\n",
            "[Forward Backward] converged in 115 iterations\n",
            "\n",
            "MAP reg_param:  50\n",
            "Image:  M31\n",
            "PSNR: 52.12,\n",
            " SNR: 29.69, SSIM: 1.0\n",
            "gamma_alpha:  291224.56316091184\n",
            "fun(x_map).item():  223242.9856397228\n",
            "tau_alpha*np.sqrt(N) + N:  67981.57752118903\n",
            "M31 _gamma_alpha:  291224.56316091184\n",
            "M31 -MAP_potential:  223242.9856397228\n",
            "Calculating credible interval for image of size:  (256, 256)\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "[Bisection Method] There is no root in this range.\n",
            "M31 _lci_mean_ 32 :  0.07934635123576297\n"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "\n",
        "result_dict_list = []\n",
        "\n",
        "for _img_name in img_name_list:\n",
        "\n",
        "    img_name = _img_name\n",
        "\n",
        "    result_dict = {}\n",
        "\n",
        "    map_potential_list = []\n",
        "    gamma_alpha_list = []\n",
        "    likelihood_map_potential_list = []\n",
        "    prior_map_potential_list = []\n",
        "    SNR_list = []\n",
        "    PSNR_list = []\n",
        "    lci_mean_list = []\n",
        "\n",
        "    for _reg_param in reg_param_list:\n",
        "\n",
        "        reg_param = _reg_param\n",
        "\n",
        "        # Load image and mask\n",
        "        img, mat_mask = qai.helpers.load_imgs(img_name, repo_dir)\n",
        "\n",
        "        # Aliases\n",
        "        x = img\n",
        "        ground_truth = img\n",
        "\n",
        "        torch_img = torch.tensor(np.copy(img), dtype=myType, device=device).reshape(\n",
        "            (1, 1) + img.shape\n",
        "        )\n",
        "\n",
        "        phi = qai.operators.MaskedFourier_torch(\n",
        "            shape=img.shape, ratio=0.5, mask=mat_mask, norm=\"ortho\", device=device\n",
        "        )\n",
        "\n",
        "        y = phi.dir_op(torch_img).detach().cpu().squeeze().numpy()\n",
        "\n",
        "        # Define noise level\n",
        "        eff_sigma = qai.helpers.compute_complex_sigma_noise(y, input_snr)\n",
        "        sigma = eff_sigma * np.sqrt(2)\n",
        "\n",
        "        # Generate noise\n",
        "        rng = np.random.default_rng(seed=0)\n",
        "        n_re = rng.normal(0, eff_sigma, y[y != 0].shape)\n",
        "        n_im = rng.normal(0, eff_sigma, y[y != 0].shape)\n",
        "        # Add noise\n",
        "        y[y != 0] += n_re + 1.0j * n_im\n",
        "\n",
        "        # Observation\n",
        "        torch_y = torch.tensor(np.copy(y), device=device, dtype=myComplexType).reshape(\n",
        "            (1,) + img.shape\n",
        "        )\n",
        "        # Generate first guess\n",
        "        x_init = torch.abs(phi.adj_op(torch_y))\n",
        "\n",
        "\n",
        "\n",
        "        # Define the likelihood\n",
        "        likelihood = qai.operators.L2Norm_torch(\n",
        "            sigma=sigma,\n",
        "            data=torch_y,\n",
        "            Phi=phi,\n",
        "        )\n",
        "        # Lipschitz constant computed automatically by likelihood, stored in likelihood.beta\n",
        "\n",
        "        # Define real prox\n",
        "        cvx_set_prox_op = qai.operators.RealProx_torch()\n",
        "\n",
        "        # Define the wavelet dict\n",
        "        # Define the l1 norm with dict psi\n",
        "        psi = qai.operators.DictionaryWv_torch(wavs_list, levels, shape=torch_img.shape)\n",
        "        reg_prox_op = qai.operators.L1Norm_torch(1.0, psi, op_to_coeffs=True)\n",
        "        reg_prox_op.gamma = reg_param\n",
        "\n",
        "\n",
        "        # Compute stepsize\n",
        "        alpha = 0.98 / likelihood.beta\n",
        "\n",
        "\n",
        "        # Run the optimisation\n",
        "        x_hat, diagnostics = qai.optim.FISTA_torch(\n",
        "            x_init,\n",
        "            options=options,\n",
        "            likelihood=likelihood,\n",
        "            cvx_set_prox_op=cvx_set_prox_op,\n",
        "            reg_prox_op=reg_prox_op,\n",
        "            alpha=alpha,\n",
        "            tau=alpha,\n",
        "            viewer=None,\n",
        "        )\n",
        "\n",
        "\n",
        "        # Convert to numpy\n",
        "        np_x_init = to_numpy(x_init)\n",
        "        x_map = x_hat.clone()\n",
        "        x_gt = np.copy(x)\n",
        "        np_x_gt = np.copy(x)\n",
        "        np_x_map = to_numpy(x_map)\n",
        "\n",
        "\n",
        "        print('\\nMAP reg_param: ', reg_param)\n",
        "        print('Image: ', img_name)\n",
        "        print('PSNR: {},\\n SNR: {}, SSIM: {}'.format(\n",
        "            round(psnr(x_gt, np_x_map, data_range=x_gt.max()-x_gt.min()), 2),\n",
        "            round(qai.utils.eval_snr(x_gt, np_x_map), 2),\n",
        "            round(ssim(x_gt, np_x_map, data_range=x_gt.max()-x_gt.min()), 2),\n",
        "        ))\n",
        "\n",
        "        SNR_list.append(qai.utils.eval_snr(x_gt, np_x_map))\n",
        "        PSNR_list.append(psnr(x_gt, np_x_map, data_range=x_gt.max()-x_gt.min()))\n",
        "\n",
        "\n",
        "        # To tensor\n",
        "        x_map_torch = x_map.clone() # to_tensor(x_map)\n",
        "\n",
        "        # Compute stepsize\n",
        "        alpha = 0.98 / likelihood.beta\n",
        "\n",
        "        #function handles for the hypothesis test\n",
        "\n",
        "        # Evaluation of the potentials\n",
        "        # Prior potential\n",
        "        prior_fun = lambda _x : reg_prox_op._fun_coeffs(reg_prox_op.dir_op(_x))\n",
        "        # Posterior potential\n",
        "        fun = lambda _x : likelihood.fun(_x) +  prior_fun(_x)\n",
        "        # Evaluation of the potential in numpy\n",
        "        fun_np = lambda _x : fun(to_tensor(_x, dtype=myType)).item()\n",
        "\n",
        "        # Compute HPD region bound\n",
        "        N = np_x_map.size\n",
        "        tau_alpha = np.sqrt(16*np.log(3/alpha_prob))\n",
        "        gamma_alpha = fun(x_map_torch).item() + tau_alpha * np.sqrt(N) + N\n",
        "\n",
        "        print('gamma_alpha: ', gamma_alpha)\n",
        "        print('fun(x_map).item(): ', fun(x_map_torch).item())\n",
        "        print('tau_alpha*np.sqrt(N) + N: ', tau_alpha*np.sqrt(N) + N)\n",
        "\n",
        "        # Compute potential\n",
        "        map_potential = fun(x_map_torch).item()\n",
        "\n",
        "        # Decompose potentials\n",
        "        map_likelihood_potential = likelihood.fun(x_map_torch).item()\n",
        "        map_prior_potential = prior_fun(x_map_torch).item()\n",
        "\n",
        "        # Print values\n",
        "        print(img_name, '_gamma_alpha: ', gamma_alpha)\n",
        "        print(img_name, '-MAP_potential: ', map_potential)\n",
        "\n",
        "        # Save values\n",
        "        map_potential_list.append(map_potential)\n",
        "        gamma_alpha_list.append(gamma_alpha)\n",
        "\n",
        "        # Save decomposed potentials\n",
        "        likelihood_map_potential_list.append(map_likelihood_potential)\n",
        "        prior_map_potential_list.append(map_prior_potential)\n",
        "\n",
        "\n",
        "        ### MAP-based UQ\n",
        "\n",
        "        # Define prior potential\n",
        "        fun_prior = lambda _x: reg_prox_op._fun_coeffs(reg_prox_op.dir_op(_x))\n",
        "        # Define posterior potential\n",
        "        loss_fun_torch = lambda _x: likelihood.fun(_x) + fun_prior(_x)\n",
        "        # Numpy version of the posterior potential\n",
        "        loss_fun_np = (\n",
        "            lambda _x: likelihood.fun(qai.utils.to_tensor(_x, dtype=myType)).item()\n",
        "            + fun_prior(qai.utils.to_tensor(_x, dtype=myType)).item()\n",
        "        )\n",
        "\n",
        "        # Compute HPD region bound\n",
        "        N = np_x_map.size\n",
        "        tau_alpha = np.sqrt(16 * np.log(3 / alpha_prob))\n",
        "        gamma_alpha = loss_fun_torch(x_hat).item() + tau_alpha * np.sqrt(N) + N\n",
        "\n",
        "        # Compute the LCI\n",
        "        error_p_arr = []\n",
        "        error_m_arr = []\n",
        "        mean_img_arr = []\n",
        "        computing_time = []\n",
        "        lci_mean = []\n",
        "\n",
        "        x_init_np = qai.utils.to_numpy(x_init)\n",
        "\n",
        "        # Compute ground truth block\n",
        "        gt_mean_img_arr = []\n",
        "        for superpix_size in superpix_MAP_sizes:\n",
        "            mean_image = ski.measure.block_reduce(\n",
        "                np.copy(img), block_size=(superpix_size, superpix_size), func=np.mean\n",
        "            )\n",
        "            gt_mean_img_arr.append(mean_image)\n",
        "\n",
        "        # Define prefix\n",
        "        save_MAP_prefix = \"{:s}_wavelets_UQ_MAP_reg_param_{:.1e}\".format(\n",
        "            img_name, reg_param\n",
        "        )\n",
        "\n",
        "        for it_pixs, superpix_size in enumerate(superpix_MAP_sizes):\n",
        "            pr_time_1 = time.process_time()\n",
        "            wall_time_1 = time.time()\n",
        "\n",
        "            error_p, error_m, mean = qai.map_uncertainty.create_local_credible_interval(\n",
        "                x_sol=np_x_map,\n",
        "                region_size=superpix_size,\n",
        "                function=loss_fun_np,\n",
        "                bound=gamma_alpha,\n",
        "                iters=LCI_iters,\n",
        "                tol=LCI_tol,\n",
        "                bottom=LCI_bottom,\n",
        "                top=LCI_top,\n",
        "            )\n",
        "            pr_time_2 = time.process_time()\n",
        "            wall_time_2 = time.time()\n",
        "            # Add values to array to save it later\n",
        "            error_p_arr.append(np.copy(error_p))\n",
        "            error_m_arr.append(np.copy(error_m))\n",
        "            mean_img_arr.append(np.copy(mean))\n",
        "            computing_time.append((pr_time_2 - pr_time_1, wall_time_2 - wall_time_1))\n",
        "            # Clip plot values\n",
        "            error_length = qai.utils.clip_matrix(\n",
        "                np.copy(error_p), clip_low_val, clip_high_val\n",
        "            ) - qai.utils.clip_matrix(np.copy(error_m), clip_low_val, clip_high_val)\n",
        "            # Recover the ground truth mean\n",
        "            gt_mean = gt_mean_img_arr[it_pixs]\n",
        "\n",
        "            lci_mean.append(np.mean(error_length))\n",
        "            print(img_name, '_lci_mean_', superpix_size,': ', np.mean(error_length))\n",
        "\n",
        "\n",
        "        lci_mean_list.append(lci_mean)\n",
        "\n",
        "\n",
        "    result_dict = {\n",
        "        'map_potential_list': map_potential_list,\n",
        "        'gamma_alpha_list': gamma_alpha_list,\n",
        "        'likelihood_map_potential_list': likelihood_map_potential_list,\n",
        "        'prior_map_potential_list': prior_map_potential_list,\n",
        "        'SNR_list': SNR_list,\n",
        "        'PSNR_list': PSNR_list,\n",
        "        'lci_mean_list': lci_mean_list,\n",
        "    }\n",
        "    # Save dict in result list\n",
        "    result_dict_list.append(result_dict)\n",
        "\n",
        "\n",
        "save_path = \"/disk/xray0/tl3/repos/QuantifAI/dev/tmp_results/reg_strength_sara/reg_strength_sara.npy\"\n",
        "\n",
        "np.save(save_path, result_dict_list, allow_pickle=True)    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "convex_uq",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "2bb75ebd6ceb1eff2ce987e124c91bc6f99e62fd1930d98a82dc138614104eef"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
